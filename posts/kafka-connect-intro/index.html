<!DOCTYPE html><html lang="en-US" mode="light" ><head><meta http-equiv="Content-Type" content="text/html; charset=UTF-8"><meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no"><meta name="generator" content="Jekyll v4.4.1" /><meta property="og:title" content="Kafka Connect 알아보기" /><meta property="og:locale" content="en_US" /><meta name="description" content="Kafka Connect Apache Kafka와 다른 데이터 시스템 간에, 데이터를 확장 가능하고 안정적으로 스트리밍하기 위한 도구" /><meta property="og:description" content="Kafka Connect Apache Kafka와 다른 데이터 시스템 간에, 데이터를 확장 가능하고 안정적으로 스트리밍하기 위한 도구" /><link rel="canonical" href="https://zz9z9.github.io/posts/kafka-connect-intro/" /><meta property="og:url" content="https://zz9z9.github.io/posts/kafka-connect-intro/" /><meta property="og:site_name" content="zz9z9" /><meta property="og:type" content="article" /><meta property="article:published_time" content="2025-10-27T22:50:00+09:00" /><meta name="twitter:card" content="summary" /><meta property="twitter:title" content="Kafka Connect 알아보기" /><meta name="twitter:site" content="@twitter_username" /> <script type="application/ld+json"> {"@context":"https://schema.org","@type":"BlogPosting","dateModified":"2025-10-27T22:50:00+09:00","datePublished":"2025-10-27T22:50:00+09:00","description":"Kafka Connect Apache Kafka와 다른 데이터 시스템 간에, 데이터를 확장 가능하고 안정적으로 스트리밍하기 위한 도구","headline":"Kafka Connect 알아보기","mainEntityOfPage":{"@type":"WebPage","@id":"https://zz9z9.github.io/posts/kafka-connect-intro/"},"url":"https://zz9z9.github.io/posts/kafka-connect-intro/"}</script><title>Kafka Connect 알아보기 | zz9z9</title><link rel="apple-touch-icon" sizes="180x180" href="/assets/img/favicons/apple-touch-icon.png"><link rel="icon" type="image/png" sizes="32x32" href="/assets/img/favicons/favicon-32x32.png"><link rel="icon" type="image/png" sizes="16x16" href="/assets/img/favicons/favicon-16x16.png"><link rel="manifest" href="/assets/img/favicons/site.webmanifest"><link rel="shortcut icon" href="/assets/img/favicons/favicon.ico"><meta name="apple-mobile-web-app-title" content="zz9z9"><meta name="application-name" content="zz9z9"><meta name="msapplication-TileColor" content="#da532c"><meta name="msapplication-config" content="/assets/img/favicons/browserconfig.xml"><meta name="theme-color" content="#ffffff"><link rel="preconnect" href="https://fonts.gstatic.com" crossorigin="anonymous"><link rel="dns-prefetch" href="https://fonts.gstatic.com"><link rel="preconnect" href="https://www.google-analytics.com" crossorigin="use-credentials"><link rel="dns-prefetch" href="https://www.google-analytics.com"><link rel="preconnect" href="https://www.googletagmanager.com" crossorigin="anonymous"><link rel="dns-prefetch" href="https://www.googletagmanager.com"><link rel="preconnect" href="https://cdn.jsdelivr.net"><link rel="dns-prefetch" href="https://cdn.jsdelivr.net"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/bootstrap@4.0.0/dist/css/bootstrap.min.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fortawesome/fontawesome-free@5.11.2/css/all.min.css"><link rel="stylesheet" href="/assets/css/style.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/gh/afeld/bootstrap-toc@1.0.1/dist/bootstrap-toc.min.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/magnific-popup@1.1.0/dist/magnific-popup.min.css"> <script src="https://cdn.jsdelivr.net/npm/jquery@3/dist/jquery.min.js"></script> <script defer src="https://cdn.jsdelivr.net/combine/npm/popper.js@1.15.0,npm/bootstrap@4/dist/js/bootstrap.min.js"></script> <script src="https://cdn.jsdelivr.net/combine/npm/lozad/dist/lozad.min.js,npm/magnific-popup@1/dist/jquery.magnific-popup.min.js"></script> <script defer src="/assets/js/dist/post.min.js"></script> <script defer src="/app.js"></script> <script defer src="https://www.googletagmanager.com/gtag/js?id=G-Q7PWLG5WYT"></script> <script> document.addEventListener("DOMContentLoaded", function(event) { window.dataLayer = window.dataLayer || []; function gtag(){dataLayer.push(arguments);} gtag('js', new Date()); gtag('config', 'G-Q7PWLG5WYT'); }); </script><body data-spy="scroll" data-target="#toc"><div id="sidebar" class="d-flex flex-column align-items-end"><div class="profile-wrapper text-center"><div id="avatar"> <a href="/" alt="avatar" class="mx-auto"> <img src="https://upload.wikimedia.org/wikipedia/commons/thumb/d/d3/Soccerball.svg/1000px-Soccerball.svg.png" alt="avatar" onerror="this.style.display='none'"> </a></div><div class="site-title mt-3"> <a href="/">zz9z9</a></div><div class="site-subtitle font-italic">거창한 계획보다는, 꾸준한 실행을</div></div><ul class="w-100"><li class="nav-item"> <a href="/" class="nav-link"> <i class="fa-fw fas fa-home ml-xl-3 mr-xl-3 unloaded"></i> <span>HOME</span> </a><li class="nav-item"> <a href="/categories/" class="nav-link"> <i class="fa-fw fas fa-stream ml-xl-3 mr-xl-3 unloaded"></i> <span>CATEGORIES</span> </a><li class="nav-item"> <a href="/tags/" class="nav-link"> <i class="fa-fw fas fa-tags ml-xl-3 mr-xl-3 unloaded"></i> <span>TAGS</span> </a><li class="nav-item"> <a href="/archives/" class="nav-link"> <i class="fa-fw fas fa-archive ml-xl-3 mr-xl-3 unloaded"></i> <span>ARCHIVES</span> </a><li class="nav-item"> <a href="/about/" class="nav-link"> <i class="fa-fw fas fa-info ml-xl-3 mr-xl-3 unloaded"></i> <span>ABOUT</span> </a></ul><div class="sidebar-bottom mt-auto d-flex flex-wrap justify-content-center"> <a href="https://github.com/zz9z9" aria-label="github" target="_blank" rel="noopener"> <i class="fab fa-github-alt"></i> </a> <a href="https://twitter.com/twitter_username" aria-label="twitter" target="_blank" rel="noopener"> <i class="fab fa-twitter"></i> </a> <a href=" javascript:location.href = 'mailto:' + ['example','doamin.com'].join('@')" aria-label="email" > <i class="fas fa-envelope"></i> </a> <a href="/feed.xml" aria-label="rss" > <i class="fas fa-rss"></i> </a></div></div><div id="topbar-wrapper" class="row justify-content-center topbar-down"><div id="topbar" class="col-11 d-flex h-100 align-items-center justify-content-between"> <span id="breadcrumb"> <span> <a href="/"> Posts </a> </span> <span>Kafka Connect 알아보기</span> </span> <i id="sidebar-trigger" class="fas fa-bars fa-fw"></i><div id="topbar-title"> Post</div><i id="search-trigger" class="fas fa-search fa-fw"></i> <span id="search-wrapper" class="align-items-center"> <i class="fas fa-search fa-fw"></i> <input class="form-control" id="search-input" type="search" aria-label="search" autocomplete="off" placeholder="Search..."> <i class="fa fa-times-circle fa-fw" id="search-cleaner"></i> </span> <span id="search-cancel" >Cancel</span></div></div><div id="main-wrapper"><div id="main"><div class="row"><div id="post-wrapper" class="col-12 col-lg-11 col-xl-8"><div class="post pl-1 pr-1 pl-sm-2 pr-sm-2 pl-md-4 pr-md-4"><h1 data-toc-skip>Kafka Connect 알아보기</h1><div class="post-meta text-muted d-flex flex-column"><div> <span class="semi-bold"> Lee JaeYoon </span> <span class="timeago " data-toggle="tooltip" data-placement="bottom" title="Mon, Oct 27, 2025, 10:50 PM +0900" prep="on" > Oct 27, 2025 <i class="unloaded">2025-10-27T22:50:00+09:00</i> </span></div><div> <span class="readtime" data-toggle="tooltip" data-placement="bottom" title="3866 words">21 min</span></div></div><div class="post-content"><h2 id="kafka-connect">Kafka Connect</h2><hr /><blockquote><p><strong>Apache Kafka와 다른 데이터 시스템</strong> 간에, 데이터를 확장 가능하고 안정적으로 <strong>스트리밍</strong>하기 위한 도구</p></blockquote><ul><li>대규모 데이터를 Kafka로 가져오거나 Kafka에서 내보내는 커넥터를 빠르고 간단하게 정의할 수 있게 해준다.<li>전체 데이터베이스를 가져오거나, 애플리케이션 서버 전반에서 수집한 메트릭(metrics)을 Kafka 토픽으로 전송하여 낮은 지연(latency)으로 스트림 처리에 활용할 수 있다.<li>내보내기 작업(export job)을 통해 Kafka 토픽의 데이터를 보조 스토리지나 조회 시스템, 또는 배치(batch) 시스템으로 전달하여 오프라인 분석에 사용할 수도 있다.</ul><h3 id="주요-특징">주요 특징</h3><p><strong>1. Kafka 커넥터를 위한 공통 프레임워크</strong></p><ul><li>Kafka Connect는 <strong>외부 데이터 시스템과 Kafka 간의 통합을 표준화</strong>하여, 커넥터의 개발·배포·관리를 단순화한다.</ul><p><strong>2. 분산(distributed) 모드와 단일(standalone) 모드 지원</strong></p><ul><li>대규모 중앙 관리형 서비스로 확장하거나, 개발·테스트·소규모 운영 환경에 맞게 축소하여 사용할 수 있다.</ul><p><strong>3. REST 인터페이스 제공</strong></p><ul><li>간단한 REST API를 통해 Kafka Connect 클러스터에 커넥터를 등록하고 관리할 수 있다.</ul><p><strong>4. 자동 오프셋(offset) 관리</strong></p><ul><li>커넥터가 최소한의 정보만 제공해도 Kafka Connect가 오프셋 커밋 과정을 자동으로 관리한다.</ul><p><strong>5. 분산 및 확장 가능 구조</strong></p><ul><li>Kafka Connect는 Kafka의 그룹 관리 프로토콜(group management protocol)을 기반으로, 워커를 추가하기만 해도 클러스터 규모를 손쉽게 확장할 수 있다.</ul><h2 id="핵심-개념">핵심 개념</h2><hr /><h3 id="1-connectors">1. Connectors</h3><blockquote><p>Kafka Connect의 커넥터(connector)는 <strong>데이터가 어디에서 어디로 복사되어야 하는지</strong>를 정의</p></blockquote><p><strong>Source Connector</strong></p><ul><li>외부 데이터 소스에서 전체 데이터베이스를 가져오고, 테이블의 변경 사항을 실시간으로 <strong>Kafka 토픽으로 스트리밍</strong></ul><p>※ “전체 데이터베이스를 가져온다 (ingest entire database)” ?</p><ul><li><p>단순히 DB 전체를 한 번에 복사한다는 뜻이 아니라, <strong>초기 데이터 적재 단계에서의 동작</strong>을 의미</p><li>초기 적재 (Initial Snapshot / Full Load)<ul><li>CDC 파이프라인을 처음 시작할 때, 현재 데이터베이스에 들어있는 <strong>모든 테이블의 전체 데이터</strong>를 한 번 읽어서 Kafka로 보내는 단계<li>CDC는 원래 “변경 사항만 감지”하지만, 시스템이 처음 시작할 때는 “기존 데이터”가 Kafka에 없기 때문에 초기 스냅샷이 필요<li>예시: MySQL의 경우, Debezium이 처음 시작할 때 각 테이블을 <code class="language-plaintext highlighter-rouge">SELECT * FROM table</code> 식으로 읽음.<li>그 데이터를 Kafka 토픽에 넣어 “현재 상태”를 맞춘 뒤, 이후부터는 binlog 기반의 변경 이벤트만 처리.</ul><li><p>따라서, 테이블 크기가 크면, <code class="language-plaintext highlighter-rouge">전체 스캔(Full Table Scan)</code>, <code class="language-plaintext highlighter-rouge">네트워크 전송 (DB → Kafka Connect)</code>, <code class="language-plaintext highlighter-rouge">JSON 직렬화 → Kafka 발행</code>까지 다 포함되어, DB I/O, 네트워크, Kafka 전송 지연이 한꺼번에 누적된다.</p><li>Debezium 설정 <code class="language-plaintext highlighter-rouge">snapshot.mode</code>로 스냅샷 방식을 제어할 수 있다.</ul><div class="table-wrapper"><table><thead><tr><th>모드<th>설명<tbody><tr><td><code class="language-plaintext highlighter-rouge">initial</code><td>(기본값) 전체 데이터를 한 번 읽은 뒤 binlog로 전환<tr><td><code class="language-plaintext highlighter-rouge">schema_only</code><td>스키마만 가져오고 실제 데이터는 binlog로만 반영<tr><td><code class="language-plaintext highlighter-rouge">never</code><td>스냅샷 생략, 이미 target이 동기화되어 있는 경우 사용<tr><td><code class="language-plaintext highlighter-rouge">initial_only</code><td>binlog로 넘어가지 않고 스냅샷까지만 수행</table></div><p><strong>Sink Connector</strong></p><ul><li><p>Kafka 토픽에 저장된 데이터를 외부 시스템으로 내보내는 역할</p><li>커넥터가 구현하거나 사용하는 모든 클래스는 커넥터 플러그인(connector plugin) 안에 정의되어 있습니다.<li><p>즉, “커넥터 플러그인(plugin)”은 코드(클래스, 설정 등)가 들어 있는 구현 단위, “커넥터 인스턴스(instance)”는 그 플러그인을 실제로 실행 중인 작업 단위라고 할 수 있습니다.</p><li>둘 다 “커넥터(connector)”라고 부르기도 하지만, 맥락에 따라 의미가 구분됩니다.<li><p>예를 들어, “install a connector(커넥터를 설치한다)” → 플러그인(plugin)을 의미 “check the status of a connector(커넥터 상태를 확인한다)” → 인스턴스(instance)를 의미</p><li>Confluent는 사용자가 가능한 한 <a href="https://www.confluent.io/product/connectors">기존 커넥터</a>를 활용할 것을 권장</ul><p>※ Confluent ?</p><blockquote><p><a href="https://www.confluent.io/">https://www.confluent.io/</a></p></blockquote><ul><li>Apache Kafka의 상용 배포판을 만든 회사이자, Kafka의 창시자인 Jay Kreps가 공동 창립한 회사</ul><div class="table-wrapper"><table><thead><tr><th>항목<th>설명<tbody><tr><td><strong>Kafka Connect</strong><td>Apache Kafka의 공식 컴포넌트 (데이터 통합 프레임워크)<tr><td><strong>Confluent</strong><td>Kafka 및 Connect를 포함한 상용 배포/운영 플랫폼<tr><td><strong>Confluent Platform</strong><td>Kafka Connect + Schema Registry + ksqlDB + 관리도구 등 포함<tr><td><strong>Confluent Cloud</strong><td>완전관리형 Kafka 서비스 (Kafka Connect 포함)</table></div><h3 id="2-tasks">2. Tasks</h3><blockquote><p>Task가 실제로 데이터를 복사하는 작업을 수행</p></blockquote><ul><li>각 커넥터 인스턴스(connector instance)는 여러 개의 태스크(task)를 조정<li><p>커넥터가 하나의 작업(job)을 여러 태스크로 나누어 병렬로 실행할 수 있게 함으로써, Kafka Connect는 병렬 처리(parallelism) 와 확장 가능한 데이터 복제(scalable data copying) 를 복잡한 설정 없이도 기본적으로 지원</p><li>각 태스크 자체는 내부적으로 상태(state)를 저장하지 않습니다.<li>대신 태스크의 상태 정보는 Kafka의 특별한 토픽에 저장됩니다:<ul><li><code class="language-plaintext highlighter-rouge">config.storage.topic</code><li><code class="language-plaintext highlighter-rouge">status.storage.topic</code></ul><li>이 상태들은 해당 커넥터 인스턴스가 관리합니다. 즉, 태스크는 무상태(stateless) 로 설계되어 있고, 필요할 때마다 Kafka 내부 토픽을 통해 상태를 복구하거나 관리할 수 있다.<li>태스크는 언제든지 시작(start), 중지(stop), 재시작(restart) 할 수 있습니다. 이런 구조 덕분에 Kafka Connect는 장애 복구(resilience) 와 확장성(scalability) 을 동시에 갖춘 안정적인 데이터 파이프라인을 제공</ul><p><img src="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-src="https://cdn.jsdelivr.net/gh/zz9z9/zz9z9.github.io@master/assets/img/kafka-connect-img1.png" alt="img.png" /> (출처 : <a href="https://docs.confluent.io/platform/current/connect/index.html">https://docs.confluent.io/platform/current/connect/index.html</a>)</p><p><strong>Task Rebalancing</strong></p><ul><li>Kafka Connect에서 커넥터가 클러스터에 처음 등록되면, 클러스터 내의 모든 워커(worker)들이 협력하여 모든 커넥터와 태스크를 재분배(rebalance) 합니다.<li><p>이 과정을 통해 <strong>각 워커는 대략 동일한 양의 작업을 담당</strong>하게 됩니다.</p><li>리밸런싱 절차는 다음과 같은 상황에서도 수행됩니다:<ul><li>커넥터가 필요한 태스크 개수를 늘리거나 줄일 때<li>커넥터의 설정이 변경될 때<li>워커가 장애로 인해 중단되었을 때, 남아 있는 활성 워커(active workers)들로 태스크가 재분배됨</ul><li><p>즉, 클러스터는 항상 <strong>부하를 균등하게 분산시키는 방향으로 자동 조정</strong>된다.</p><li>태스크가 개별적으로 실패했을 때(task failure)는 리밸런싱이 자동으로 트리거되지 않는다.<ul><li>태스크 실패는 일반적인 운영 시나리오가 아닌 예외적인 상황으로 간주되기 때문입니다.<li>따라서, 실패한 태스크는 Kafka Connect 프레임워크가 자동으로 재시작하지 않습니다.<li>대신 REST API 를 통해 수동으로 재시작해야 합니다.</ul></ul><p><img src="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-src="https://cdn.jsdelivr.net/gh/zz9z9/zz9z9.github.io@master/assets/img/kafka-connect-img2.png" alt="img.png" /> (출처 : <a href="https://docs.confluent.io/platform/current/connect/index.html">https://docs.confluent.io/platform/current/connect/index.html</a>)</p><h3 id="3-workers">3. Workers</h3><blockquote><p>커넥터(Connector) 와 태스크(Task) 는 논리적인 작업 단위이므로, 이들이 실제로 실행되기 위해서는 어떤 프로세스(process) 위에 스케줄링되어야 합니다. <br /> Kafka Connect에서는 이러한 프로세스를 워커(Worker) 라고 부릅니다.</p></blockquote><p><strong>Standalone Workers (단일 모드 워커)</strong></p><ul><li><p>Standalone 모드는 가장 단순한 실행 모드입니다. 하나의 프로세스가 모든 커넥터와 태스크를 직접 실행합니다.</p><li>특징:<ul><li>설정이 매우 간단 (단일 프로세스만 실행)<li>개발 초기 단계나 테스트, 또는 단일 호스트에서 로그를 수집하는 등의 간단한 상황에 적합<li>모든 실행이 하나의 프로세스에서 처리됨</ul><li>제한점:<ul><li>확장성(scalability) 이 제한됨 (프로세스 1개가 전부)<li>장애 복구(fault tolerance) 불가능 (프로세스가 죽으면 전체 중단)<li>외부 모니터링을 붙이지 않으면 자동 복구 기능 없음</ul></ul><p><strong>Distributed Workers (분산 모드 워커)</strong></p><blockquote><p>Kafka Connect의 확장성(scalability)과 자동 장애 복구(fault tolerance)를 제공하는 운영 환경용 모드</p></blockquote><ul><li>특징:<ul><li>여러 워커 프로세스를 동일한 group.id 로 실행하면, 이들이 하나의 Connect 클러스터를 형성함.<li>워커들이 서로 협력하여 커넥터와 태스크를 자동으로 분산 배치.<li>워커를 추가하거나 중단하거나 장애가 발생하면, 남은 워커들이 이를 감지하고 태스크를 자동 재분배(rebalance) 함.<li>이 과정은 Kafka Consumer Group 리밸런싱과 유사한 방식으로 동작함.</ul><li>예시:<ul><li>Worker A: <code class="language-plaintext highlighter-rouge">group.id = connect-cluster-a</code><li>Worker B: <code class="language-plaintext highlighter-rouge">group.id = connect-cluster-a</code><li>두 워커는 자동으로 하나의 클러스터 connect-cluster-a 를 형성함.</ul></ul><p><img src="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-src="https://cdn.jsdelivr.net/gh/zz9z9/zz9z9.github.io@master/assets/img/kafka-connect-img3.png" alt="img.png" /> (출처 : <a href="https://docs.confluent.io/platform/current/connect/index.html">https://docs.confluent.io/platform/current/connect/index.html</a>)</p><h3 id="4-converters">4. Converters</h3><blockquote><p>Kafka Connect가 외부 시스템과 데이터를 주고받을 때, 데이터를 Kafka 내부 형식<strong>(바이트 배열)</strong>과 Connect의 내부 데이터 구조 사이에서 변환해주는 역할</p></blockquote><ul><li><p>즉, Task가 데이터를 처리할 때, 컨버터를 사용하여 <strong>바이트 형태의 데이터를 Kafka Connect 내부 데이터 형식으로 변환</strong>하거나, 반대로 <strong>내부 형식을 바이트로 직렬화</strong></p><li><p>예시:</p></ul><div class="table-wrapper"><table><thead><tr><th>컨버터<th>설명<tbody><tr><td><strong>JsonConverter</strong><td>데이터를 JSON 형태로 변환<tr><td><strong>StringConverter</strong><td>단순 문자열로 변환<tr><td><strong>AvroConverter</strong><td>Avro 스키마를 기반으로 변환 (주로 Schema Registry와 함께 사용)<tr><td><strong>ProtobufConverter</strong><td>Protobuf 포맷으로 직렬화/역직렬화<tr><td><strong>ByteArrayConverter</strong><td>원시 바이트 그대로 처리 (가공 없이 전송할 때)</table></div><ul><li>컨버터는 커넥터로부터 독립적으로 분리되어 설계되어 있다.<ul><li>따라서, 커넥터는 자신이 다루는 데이터 소스나 타깃(DB, 파일 등)에 집중할 수 있고<li>데이터의 표현 방식(Avro, JSON, String 등)은 컨버터가 전담</ul></ul><p><img src="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-src="https://cdn.jsdelivr.net/gh/zz9z9/zz9z9.github.io@master/assets/img/kafka-connect-img4.png" alt="img.png" /> (출처 : <a href="https://docs.confluent.io/platform/current/connect/index.html">https://docs.confluent.io/platform/current/connect/index.html</a>)</p><h3 id="5-transforms">5. Transforms</h3><blockquote><p>하나의 레코드를 입력받아 수정된 레코드를 출력하는 간단한 함수</p></blockquote><ul><li>레코드 ?<ul><li>커넥터가 주고받는 <strong>한 건의 데이터 이벤트</strong>를 의미<li>Source Connector → Kafka 로 데이터를 보낼 때: <code class="language-plaintext highlighter-rouge">SourceRecord</code><li>Kafka → Sink Connector 로 데이터를 보낼 때: <code class="language-plaintext highlighter-rouge">SinkRecord</code></ul><li><code class="language-plaintext highlighter-rouge">orders</code> 테이블에서 한 행이 변경됐을때, Debezium 같은 Source Connector가 다음과 같은 <code class="language-plaintext highlighter-rouge">SourceRecord</code> 를 생성</ul><div class="language-json highlighter-rouge"><div class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
2
3
4
5
6
7
8
9
10
11
</pre><td class="rouge-code"><pre><span class="p">{</span><span class="w">
  </span><span class="nl">"topic"</span><span class="p">:</span><span class="w"> </span><span class="s2">"dbserver1.inventory.orders"</span><span class="p">,</span><span class="w">
  </span><span class="nl">"key"</span><span class="p">:</span><span class="w"> </span><span class="p">{</span><span class="w"> </span><span class="nl">"order_id"</span><span class="p">:</span><span class="w"> </span><span class="mi">101</span><span class="w"> </span><span class="p">},</span><span class="w">
  </span><span class="nl">"value"</span><span class="p">:</span><span class="w"> </span><span class="p">{</span><span class="w">
    </span><span class="nl">"order_id"</span><span class="p">:</span><span class="w"> </span><span class="mi">101</span><span class="p">,</span><span class="w">
    </span><span class="nl">"status"</span><span class="p">:</span><span class="w"> </span><span class="s2">"SHIPPED"</span><span class="p">,</span><span class="w">
    </span><span class="nl">"amount"</span><span class="p">:</span><span class="w"> </span><span class="mi">30000</span><span class="w">
  </span><span class="p">},</span><span class="w">
  </span><span class="nl">"timestamp"</span><span class="p">:</span><span class="w"> </span><span class="mi">1735200000000</span><span class="p">,</span><span class="w">
  </span><span class="nl">"schema"</span><span class="p">:</span><span class="w"> </span><span class="p">{</span><span class="w"> </span><span class="err">...</span><span class="w"> </span><span class="p">}</span><span class="w">
</span><span class="p">}</span><span class="w">
</span></pre></table></code></div></div><p><strong>Source Connector에서의 Transform 동작</strong></p><blockquote><p><code class="language-plaintext highlighter-rouge">Source Connector → Transform 1 → Transform 2 → … → Kafka</code></p></blockquote><ul><li>Source Connector 가 새로운 소스 레코드를 생성하면, Kafka Connect는 그 레코드를 첫 번째 변환(Transform)으로 전달한다.<li>변환이 수행되어 수정된 새로운 레코드가 생성된다.<li>이 결과 레코드는 다음 변환으로 전달되고, 같은 방식으로 반복된다.<li>마지막 변환을 거친 최종 레코드는 바이너리 형태로 직렬화되어 Kafka에 저장된다.</ul><p><strong>Sink Connector에서의 Transform 동작</strong></p><blockquote><p><code class="language-plaintext highlighter-rouge">Kafka → Transform 1 → Transform 2 → … → Sink Connector</code></p></blockquote><ul><li>Kafka Connect는 Kafka 토픽으로부터 메시지를 읽어 바이너리 데이터를 Sink Record 로 변환한다.<li>변환이 설정되어 있으면, 그 레코드는 첫 번째 변환을 거친다.<li>수정된 레코드는 다음 변환으로 전달되어 또 한 번 갱신된다.<li>모든 변환을 거친 최종 Sink Record가 Sink Connector 로 전달되어 최종 처리된다.</ul><p><strong>예시1</strong></p><blockquote><p>토픽 이름 변경 (RegexRouter 사용)</p></blockquote><div class="language-json highlighter-rouge"><div class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
2
3
4
</pre><td class="rouge-code"><pre><span class="nl">"transforms"</span><span class="p">:</span><span class="w"> </span><span class="s2">"routeByStatus"</span><span class="err">,</span><span class="w">
</span><span class="nl">"transforms.routeByStatus.type"</span><span class="p">:</span><span class="w"> </span><span class="s2">"org.apache.kafka.connect.transforms.RegexRouter"</span><span class="err">,</span><span class="w">
</span><span class="nl">"transforms.routeByStatus.regex"</span><span class="p">:</span><span class="w"> </span><span class="s2">"orders"</span><span class="err">,</span><span class="w">
</span><span class="nl">"transforms.routeByStatus.replacement"</span><span class="p">:</span><span class="w"> </span><span class="s2">"orders.${order_status}"</span><span class="w">
</span></pre></table></code></div></div><ul><li><code class="language-plaintext highlighter-rouge">RegexRouter</code> 변환은 메시지가 들어가는 토픽 이름을 동적으로 변경한다.<ul><li><code class="language-plaintext highlighter-rouge">${order_status}</code> 같은 필드를 사용해 메시지 값(value)에 따라 라우팅이 가능 (다만 기본 SMT는 값 참조를 직접 지원하지 않으므로, 커스텀 Transform으로 구현하기도 한다.)</ul><li>결과적으로, <code class="language-plaintext highlighter-rouge">orders.NEW</code>, <code class="language-plaintext highlighter-rouge">orders.CANCELLED</code>처럼 주문 상태에 따라 다른 토픽으로 전송됨</ul><p><strong>예시2</strong></p><blockquote><p>특정 필드 제거</p></blockquote><div class="language-json highlighter-rouge"><div class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
2
3
</pre><td class="rouge-code"><pre><span class="nl">"transforms"</span><span class="p">:</span><span class="w"> </span><span class="s2">"removePII"</span><span class="err">,</span><span class="w">
</span><span class="nl">"transforms.removePII.type"</span><span class="p">:</span><span class="w"> </span><span class="s2">"org.apache.kafka.connect.transforms.ReplaceField$Value"</span><span class="err">,</span><span class="w">
</span><span class="nl">"transforms.removePII.blacklist"</span><span class="p">:</span><span class="w"> </span><span class="s2">"ssn,email"</span><span class="w">
</span></pre></table></code></div></div><ul><li><code class="language-plaintext highlighter-rouge">ssn</code>, <code class="language-plaintext highlighter-rouge">email</code> 같은 개인정보 필드를 메시지에서 제거</ul><h3 id="6-dead-letter-queue">6. Dead Letter Queue</h3><blockquote><p>Sink Connector에서 처리할 수 없는 잘못된 레코드를 별도 토픽으로 보내는 에러 처리 메커니즘</p></blockquote><ul><li>Dead Letter Queue(DLQ)는 Sink Connector에서만 사용되는 기능<ul><li>즉, Sink Connector에서 <strong>형식 불일치나 변환 오류 등</strong>으로 특정 레코드를 처리할 수 없을 때, 실패한 레코드를 특별한 Kafka 토픽<strong>(Dead Letter Queue Topic)</strong>으로 따로 보관한다.<li>예시 :<ul><li>Kafka 메시지는 JSON 형식인데, Sink Connector는 Avro 형식을 기대하고 있을 때<li>메시지에 필수 필드가 누락되었을 때<li>스키마 호환성 문제로 Sink 시스템에 쓸 수 없을 때</ul></ul><li>이런 경우, Kafka Connect는 <code class="language-plaintext highlighter-rouge">errors.tolerance</code> 설정에 따라 대응한다.</ul><div class="table-wrapper"><table><thead><tr><th>설정값<th>의미<tbody><tr><td><strong>none (기본값)</strong><td>- 오류 발생 시 <strong>즉시 태스크 실패</strong>. 커넥터는 실패 상태(failed)가 되어 중단됨<br /> - 운영자는 Worker 로그를 확인하고 원인을 수정한 뒤 커넥터를 재시작해야 함<tr><td><strong>all</strong><td>- 모든 오류나 잘못된 레코드를 <strong>무시하고 계속 처리</strong>. 다만 로그에는 기록되지 않음. <br /> - 따라서, 실패한 레코드 수를 확인하려면 내부 메트릭(metrics)이나 원본과 결과의 카운트를 비교해야 한다.</table></div><ul><li><code class="language-plaintext highlighter-rouge">errors.tolerance=all</code> 로 설정된 경우, 추가 설정을 통해 실패한 레코드를 DLQ 토픽으로 자동 전송할 수 있다.</ul><div class="language-plaintext highlighter-rouge"><div class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
2
</pre><td class="rouge-code"><pre>errors.tolerance = all
errors.deadletterqueue.topic.name = &lt;dead-letter-topic-name&gt;
</pre></table></code></div></div><ul><li>기본적으로 DLQ 토픽에는 레코드 데이터만 저장되며, “왜 실패했는지”에 대한 정보가 없다.<li>아래 옵션을 추가해서 에러 메타데이터를 함께 기록할 수 있다.</ul><div class="language-plaintext highlighter-rouge"><div class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
</pre><td class="rouge-code"><pre>errors.deadletterqueue.context.headers.enable = true
</pre></table></code></div></div><ul><li>이 설정을 켜면 DLQ에 전송되는 레코드의 헤더에 에러 원인 정보가 추가된다.<li>헤더 키들은 <code class="language-plaintext highlighter-rouge">_connect.errors.</code> 로 시작하며, <code class="language-plaintext highlighter-rouge">kafkacat</code> 같은 도구로 이 헤더를 읽어보면 실패 이유를 직접 확인할 수 있다.<li>예:</ul><div class="language-plaintext highlighter-rouge"><div class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
2
</pre><td class="rouge-code"><pre>_connect.errors.exception.class=org.apache.kafka.connect.errors.DataException
_connect.errors.exception.message=Invalid schema
</pre></table></code></div></div><h2 id="참고-자료">참고 자료</h2><hr /><ul><li><a href="https://kafka.apache.org/documentation.html#connect">https://kafka.apache.org/documentation.html#connect</a><li><a href="https://docs.confluent.io/platform/current/connect/index.html">https://docs.confluent.io/platform/current/connect/index.html</a></ul></div><div class="post-tail-wrapper text-muted"><div class="post-meta mb-3"> <i class="far fa-folder-open fa-fw mr-1"></i> <a href='/categories/%EC%A7%80%EC%8B%9D-%EB%8D%94%ED%95%98%EA%B8%B0/'>지식 더하기</a>, <a href='/categories/%EC%9D%B4%EB%A1%A0/'>이론</a></div><div class="post-tags"> <i class="fa fa-tags fa-fw mr-1"></i> <a href="/tags/infra/" class="post-tag no-text-decoration" >Infra</a></div><div class="post-tail-bottom d-flex justify-content-between align-items-center mt-3 pt-5 pb-2"><div class="license-wrapper"> This post is licensed under <a href="https://creativecommons.org/licenses/by/4.0/">CC BY 4.0</a> by the author.</div><div class="share-wrapper"> <span class="share-label text-muted mr-1">Share</span> <span class="share-icons"> <a href="https://twitter.com/intent/tweet?text=Kafka Connect 알아보기 - zz9z9&url=https://zz9z9.github.io/posts/kafka-connect-intro/" data-toggle="tooltip" data-placement="top" title="Twitter" target="_blank" rel="noopener" aria-label="Twitter"> <i class="fa-fw fab fa-twitter"></i> </a> <a href="https://www.facebook.com/sharer/sharer.php?title=Kafka Connect 알아보기 - zz9z9&u=https://zz9z9.github.io/posts/kafka-connect-intro/" data-toggle="tooltip" data-placement="top" title="Facebook" target="_blank" rel="noopener" aria-label="Facebook"> <i class="fa-fw fab fa-facebook-square"></i> </a> <a href="https://telegram.me/share?text=Kafka Connect 알아보기 - zz9z9&url=https://zz9z9.github.io/posts/kafka-connect-intro/" data-toggle="tooltip" data-placement="top" title="Telegram" target="_blank" rel="noopener" aria-label="Telegram"> <i class="fa-fw fab fa-telegram"></i> </a> <i class="fa-fw fas fa-link small" onclick="copyLink()" data-toggle="tooltip" data-placement="top" title="Copy link"></i> </span></div></div></div></div></div><div id="panel-wrapper" class="col-xl-3 pl-2 text-muted topbar-down"><div class="access"><div id="access-lastmod" class="post"> <span>Recent Update</span><ul class="post-content pl-0 pb-1 ml-1 mt-2"><li><a href="/posts/jpa-entity-manager-persistence-context/">EntityManager와 영속성 컨텍스트</a><li><a href="/posts/jpa-id-generation-strategy/">JPA/Hibernate ID 생성 전략</a><li><a href="/posts/aws-vpc/">AWS VPC(Virtual Private Cloud) - 기초 개념</a><li><a href="/posts/aws-efs/">AWS EFS(Elastic File System) - 기초 개념</a><li><a href="/posts/aws-intro/">AWS - 상품 살펴보기</a></ul></div><div id="access-tags"> <span>Trending Tags</span><div class="d-flex flex-wrap mt-3 mb-1 mr-3"> <a class="post-tag" href="/tags/java/">Java</a> <a class="post-tag" href="/tags/mysql/">MySQL</a> <a class="post-tag" href="/tags/aws/">AWS</a> <a class="post-tag" href="/tags/spring/">Spring</a> <a class="post-tag" href="/tags/web/">WEB</a> <a class="post-tag" href="/tags/infra/">Infra</a> <a class="post-tag" href="/tags/jpa/">JPA</a> <a class="post-tag" href="/tags/hibernate/">Hibernate</a> <a class="post-tag" href="/tags/http/">HTTP</a> <a class="post-tag" href="/tags/spring-batch/">Spring Batch</a></div></div></div><script src="https://cdn.jsdelivr.net/gh/afeld/bootstrap-toc@1.0.1/dist/bootstrap-toc.min.js"></script><div id="toc-wrapper" class="pl-0 pr-4 mb-5"> <span class="pl-3 pt-2 mb-2">Contents</span><nav id="toc" data-toggle="toc"></nav></div></div></div><div class="row"><div class="col-12 col-lg-11 col-xl-8"><div id="post-extend-wrapper" class="pl-1 pr-1 pl-sm-2 pr-sm-2 pl-md-4 pr-md-4"><div id="related-posts" class="mt-5 mb-2 mb-sm-4"><h3 class="pt-2 mt-1 mb-4 ml-1" data-toc-skip>Further Reading</h3><div class="card-deck mb-4"><div class="card"> <a href="/posts/tomcat-server-xml-file/"><div class="card-body"> <span class="timeago small" > Apr 7, 2022 <i class="unloaded">2022-04-07T22:00:00+09:00</i> </span><h3 class="pt-0 mt-1 mb-3" data-toc-skip>Infra - 톰캣 구조 살펴보기</h3><div class="text-muted small"><p> 톰캣 구조 출처 : https://howtodoinjava.com/tomcat/tomcats-architecture-and-server-xml-configuration-tutorial/ 이러한 구조는 일반적으로 Tomcat 설치 폴더의 /conf 하위 디렉토리에 있는 server.xml 파일에 정의된다. server.xml ...</p></div></div></a></div><div class="card"> <a href="/posts/cdc-intro/"><div class="card-body"> <span class="timeago small" > Oct 26, 2025 <i class="unloaded">2025-10-26T00:50:00+09:00</i> </span><h3 class="pt-0 mt-1 mb-3" data-toc-skip>CDC(Change Data Capture) 알아보기</h3><div class="text-muted small"><p> CDC(Change Capture Data)란 ? 데이터베이스나 데이터 웨어하우스 같은 데이터 소스의 모든 변경 사항을 추적하여, 이러한 변경 내용을 대상 시스템에 반영할 수 있도록 하는 과정 (출처 : https://www.confluent.io/learn/change-data-capture/#quick-intro-to-cdc) 주요...</p></div></div></a></div><div class="card"> <a href="/posts/debezium-intro/"><div class="card-body"> <span class="timeago small" > Oct 29, 2025 <i class="unloaded">2025-10-29T22:00:00+09:00</i> </span><h3 class="pt-0 mt-1 mb-3" data-toc-skip>Debezium 알아보기</h3><div class="text-muted small"><p> Debezium Debezium은 CDC(Change Data Capture)를 위한 오픈 소스 분산 플랫폼이다. (공식 사이트) Kafka Connect의 Source Connector 플러그인 중 하나 (내가 지금까지 이해한 정도) Debezium은 Kafka Connect와 호환되는 소스 커넥터(Source Connector)...</p></div></div></a></div></div></div><div class="post-navigation d-flex justify-content-between"> <a href="/posts/cdc-intro/" class="btn btn-outline-primary" prompt="Older"><p>CDC(Change Data Capture) 알아보기</p></a> <a href="/posts/debezium-intro/" class="btn btn-outline-primary" prompt="Newer"><p>Debezium 알아보기</p></a></div></div></div></div><footer class="d-flex w-100 justify-content-center"><div class="d-flex justify-content-between align-items-center"><div class="footer-left"><p class="mb-0"> © 2026 <a href="https://twitter.com/username">Lee JaeYoon</a>. <span data-toggle="tooltip" data-placement="top" title="Except where otherwise noted, the blog posts on this site are licensed under the Creative Commons Attribution 4.0 International (CC BY 4.0) License by the author.">Some rights reserved.</span></p></div><div class="footer-right"><p class="mb-0"> Powered by <a href="https://jekyllrb.com" target="_blank" rel="noopener">Jekyll</a> with <a href="https://github.com/cotes2020/jekyll-theme-chirpy" target="_blank" rel="noopener">Chirpy</a> theme.</p></div></div></footer></div><div id="search-result-wrapper" class="d-flex justify-content-center unloaded"><div class="col-12 col-sm-11 post-content"><div id="search-hints"><h4 class="text-muted mb-4">Trending Tags</h4><a class="post-tag" href="/tags/java/">Java</a> <a class="post-tag" href="/tags/mysql/">MySQL</a> <a class="post-tag" href="/tags/aws/">AWS</a> <a class="post-tag" href="/tags/spring/">Spring</a> <a class="post-tag" href="/tags/web/">WEB</a> <a class="post-tag" href="/tags/infra/">Infra</a> <a class="post-tag" href="/tags/jpa/">JPA</a> <a class="post-tag" href="/tags/hibernate/">Hibernate</a> <a class="post-tag" href="/tags/http/">HTTP</a> <a class="post-tag" href="/tags/spring-batch/">Spring Batch</a></div><div id="search-results" class="d-flex flex-wrap justify-content-center text-muted mt-3"></div></div></div></div><div id="mask"></div><a id="back-to-top" href="#" aria-label="back-to-top" class="btn btn-lg btn-box-shadow" role="button"> <i class="fas fa-angle-up"></i> </a> <script src="https://cdn.jsdelivr.net/npm/simple-jekyll-search@1.7.3/dest/simple-jekyll-search.min.js"></script> <script> SimpleJekyllSearch({ searchInput: document.getElementById('search-input'), resultsContainer: document.getElementById('search-results'), json: '/assets/js/data/search.json', searchResultTemplate: '<div class="pl-1 pr-1 pl-sm-2 pr-sm-2 pl-lg-4 pr-lg-4 pl-xl-0 pr-xl-0"> <a href="https://zz9z9.github.io{url}">{title}</a><div class="post-meta d-flex flex-column flex-sm-row text-muted mt-1 mb-1"> {categories} {tags}</div><p>{snippet}</p></div>', noResultsText: '<p class="mt-5">Oops! No result founds.</p>', templateMiddleware: function(prop, value, template) { if (prop === 'categories') { if (value === '') { return `${value}`; } else { return `<div class="mr-sm-4"><i class="far fa-folder fa-fw"></i>${value}</div>`; } } if (prop === 'tags') { if (value === '') { return `${value}`; } else { return `<div><i class="fa fa-tag fa-fw"></i>${value}</div>`; } } } }); </script>
