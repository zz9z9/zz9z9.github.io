[CDC(Change Data Capture)ì— ëŒ€í•´ ì•Œì•„ë³´ë‹¤ë³´ë‹ˆ](https://zz9z9.github.io/posts/cdc-intro/) Kafka Connectì™€ Debeziumì´ ì—°ê´€ ë‹¨ì–´ë¡œ ë§ì´ ë³´ì˜€ë‹¤.

- CDC : source datasourceì˜ ë°ì´í„° ë³€ê²½ì„ ê°ì§€í•´ì„œ target datasourceë¡œ ì´ë™ì‹œí‚¤ëŠ” ê²ƒ
=> ì´ê±¸ ì‹¤í˜„í•˜ê¸° ìœ„í•œ ëŒ€í‘œì ì¸ ë„êµ¬ë¡œ Kafka Connect, Debeziumì´ ì‚¬ìš©ëœë‹¤ ?

- Kafka Connect
  - Kafkaì™€ ë‹¤ë¥¸ ë°ì´í„°ì†ŒìŠ¤ ê°„ì˜ ì—°ê²°ê³ ë¦¬ ì—­í•  (ë°ì´í„°ì†ŒìŠ¤, ì¹´í”„ì¹´ì™€ ì—°ê²°ë˜ê¸° ìœ„í•œ API ì •ì˜ ?)
  - ì»¤ë„¥í„°ë¥¼ ì‹¤í–‰í•˜ê³  ê´€ë¦¬í•˜ëŠ” í”„ë ˆì„ì›Œí¬ (API ë° ëŸ°íƒ€ì„ í™˜ê²½ ì œê³µ)

- Debezium
  - Kafka Connect ìœ„ì—ì„œ ë™ì‘í•˜ëŠ” CDCìš© Source Connector êµ¬í˜„ì²´
  - ì¦‰, Debeziumì€ Kafka Connectì˜ Source Connector í”ŒëŸ¬ê·¸ì¸ ì¤‘ í•˜ë‚˜

## Kafka Connect
---
> **Apache Kafkaì™€ ë‹¤ë¥¸ ë°ì´í„° ì‹œìŠ¤í…œ** ê°„ì—, ë°ì´í„°ë¥¼ í™•ì¥ ê°€ëŠ¥í•˜ê³  ì•ˆì •ì ìœ¼ë¡œ **ìŠ¤íŠ¸ë¦¬ë°**í•˜ê¸° ìœ„í•œ ë„êµ¬

- ëŒ€ê·œëª¨ ë°ì´í„°ë¥¼ Kafkaë¡œ ê°€ì ¸ì˜¤ê±°ë‚˜ Kafkaì—ì„œ ë‚´ë³´ë‚´ëŠ” ì»¤ë„¥í„°ë¥¼ ë¹ ë¥´ê³  ê°„ë‹¨í•˜ê²Œ ì •ì˜í•  ìˆ˜ ìˆê²Œ í•´ì¤€ë‹¤.
- ì „ì²´ ë°ì´í„°ë² ì´ìŠ¤ë¥¼ ê°€ì ¸ì˜¤ê±°ë‚˜, ì• í”Œë¦¬ì¼€ì´ì…˜ ì„œë²„ ì „ë°˜ì—ì„œ ìˆ˜ì§‘í•œ ë©”íŠ¸ë¦­(metrics)ì„ Kafka í† í”½ìœ¼ë¡œ ì „ì†¡í•˜ì—¬ ë‚®ì€ ì§€ì—°(latency)ìœ¼ë¡œ ìŠ¤íŠ¸ë¦¼ ì²˜ë¦¬ì— í™œìš©í•  ìˆ˜ ìˆë‹¤.
- ë‚´ë³´ë‚´ê¸° ì‘ì—…(export job)ì„ í†µí•´ Kafka í† í”½ì˜ ë°ì´í„°ë¥¼ ë³´ì¡° ìŠ¤í† ë¦¬ì§€ë‚˜ ì¡°íšŒ ì‹œìŠ¤í…œ, ë˜ëŠ” ë°°ì¹˜(batch) ì‹œìŠ¤í…œìœ¼ë¡œ ì „ë‹¬í•˜ì—¬ ì˜¤í”„ë¼ì¸ ë¶„ì„ì— ì‚¬ìš©í•  ìˆ˜ë„ ìˆë‹¤.

### ì£¼ìš” íŠ¹ì§•
**1. Kafka ì»¤ë„¥í„°ë¥¼ ìœ„í•œ ê³µí†µ í”„ë ˆì„ì›Œí¬**
- Kafka ConnectëŠ” **ì™¸ë¶€ ë°ì´í„° ì‹œìŠ¤í…œê³¼ Kafka ê°„ì˜ í†µí•©ì„ í‘œì¤€í™”**í•˜ì—¬, ì»¤ë„¥í„°ì˜ ê°œë°œÂ·ë°°í¬Â·ê´€ë¦¬ë¥¼ ë‹¨ìˆœí™”í•œë‹¤.

**2. ë¶„ì‚°(distributed) ëª¨ë“œì™€ ë‹¨ì¼(standalone) ëª¨ë“œ ì§€ì›**
- ëŒ€ê·œëª¨ ì¤‘ì•™ ê´€ë¦¬í˜• ì„œë¹„ìŠ¤ë¡œ í™•ì¥í•˜ê±°ë‚˜, ê°œë°œÂ·í…ŒìŠ¤íŠ¸Â·ì†Œê·œëª¨ ìš´ì˜ í™˜ê²½ì— ë§ê²Œ ì¶•ì†Œí•˜ì—¬ ì‚¬ìš©í•  ìˆ˜ ìˆë‹¤.

**3. REST ì¸í„°í˜ì´ìŠ¤ ì œê³µ**
- ê°„ë‹¨í•œ REST APIë¥¼ í†µí•´ Kafka Connect í´ëŸ¬ìŠ¤í„°ì— ì»¤ë„¥í„°ë¥¼ ë“±ë¡í•˜ê³  ê´€ë¦¬í•  ìˆ˜ ìˆë‹¤.

**4. ìë™ ì˜¤í”„ì…‹(offset) ê´€ë¦¬**
- ì»¤ë„¥í„°ê°€ ìµœì†Œí•œì˜ ì •ë³´ë§Œ ì œê³µí•´ë„ Kafka Connectê°€ ì˜¤í”„ì…‹ ì»¤ë°‹ ê³¼ì •ì„ ìë™ìœ¼ë¡œ ê´€ë¦¬í•œë‹¤.

**5. ë¶„ì‚° ë° í™•ì¥ ê°€ëŠ¥ êµ¬ì¡°**
- Kafka ConnectëŠ” Kafkaì˜ ê·¸ë£¹ ê´€ë¦¬ í”„ë¡œí† ì½œ(group management protocol)ì„ ê¸°ë°˜ìœ¼ë¡œ, ì›Œì»¤(worker) ë¥¼ ì¶”ê°€í•˜ê¸°ë§Œ í•´ë„ í´ëŸ¬ìŠ¤í„° ê·œëª¨ë¥¼ ì†ì‰½ê²Œ í™•ì¥í•  ìˆ˜ ìˆë‹¤.


## í•µì‹¬ ê°œë…
---

### 1. Connectors
> Kafka Connectì˜ ì»¤ë„¥í„°(connector)ëŠ” **ë°ì´í„°ê°€ ì–´ë””ì—ì„œ ì–´ë””ë¡œ ë³µì‚¬ë˜ì–´ì•¼ í•˜ëŠ”ì§€**ë¥¼ ì •ì˜

**Source Connector**
- ì™¸ë¶€ ë°ì´í„° ì†ŒìŠ¤ì—ì„œ ì „ì²´ ë°ì´í„°ë² ì´ìŠ¤ë¥¼ ê°€ì ¸ì˜¤ê³ , í…Œì´ë¸”ì˜ ë³€ê²½ ì‚¬í•­ì„ ì‹¤ì‹œê°„ìœ¼ë¡œ **Kafka í† í”½ìœ¼ë¡œ ìŠ¤íŠ¸ë¦¬ë°**

â€» â€œì „ì²´ ë°ì´í„°ë² ì´ìŠ¤ë¥¼ ê°€ì ¸ì˜¨ë‹¤ (ingest entire database)â€ ?
- ë‹¨ìˆœíˆ â€œDB ì „ì²´ë¥¼ í•œ ë²ˆì— ë³µì‚¬í•œë‹¤â€ëŠ” ëœ»ì´ ì•„ë‹ˆë¼, ì´ˆê¸° ë°ì´í„° ì ì¬(initial load) ë‹¨ê³„ì—ì„œì˜ ë™ì‘ì„ ì˜ë¯¸

âœ… 1ï¸âƒ£ ì´ˆê¸° ì ì¬ (Initial Snapshot / Full Load)

ì˜ë¯¸: CDC íŒŒì´í”„ë¼ì¸ì„ ì²˜ìŒ ì‹œì‘í•  ë•Œ,
í˜„ì¬ ë°ì´í„°ë² ì´ìŠ¤ì— ë“¤ì–´ìˆëŠ” ëª¨ë“  í…Œì´ë¸”ì˜ ì „ì²´ ë°ì´í„°ë¥¼ í•œ ë²ˆ ì½ì–´ì„œ Kafkaë¡œ ë³´ë‚´ëŠ” ë‹¨ê³„ì…ë‹ˆë‹¤.

ì´ìœ : CDCëŠ” ì›ë˜ â€œë³€ê²½ ì‚¬í•­ë§Œ ê°ì§€â€í•˜ì§€ë§Œ,
ì‹œìŠ¤í…œì´ ì²˜ìŒ ì‹œì‘í•  ë•ŒëŠ” â€œê¸°ì¡´ ë°ì´í„°â€ê°€ Kafkaì— ì—†ê¸° ë•Œë¬¸ì— ì´ˆê¸° ìŠ¤ëƒ…ìƒ·ì´ í•„ìš”í•©ë‹ˆë‹¤.

ì˜ˆì‹œ:

MySQLì˜ ê²½ìš° â†’ Debeziumì´ ì²˜ìŒ ì‹œì‘í•  ë•Œ ê° í…Œì´ë¸”ì„ SELECT * FROM table ì‹ìœ¼ë¡œ ì½ìŒ.

ê·¸ ë°ì´í„°ë¥¼ Kafka í† í”½ì— ë„£ì–´ â€œí˜„ì¬ ìƒíƒœâ€ë¥¼ ë§ì¶˜ ë’¤, ì´í›„ë¶€í„°ëŠ” binlog ê¸°ë°˜ì˜ ë³€ê²½ ì´ë²¤íŠ¸ë§Œ ì²˜ë¦¬.

âœ… 2ï¸âƒ£ ë³€ê²½ ìŠ¤íŠ¸ë¦¼ (Change Stream / Incremental Capture)

ì´ˆê¸° ìŠ¤ëƒ…ìƒ· ì´í›„ì—ëŠ” DBì˜ ë³€ê²½ ë¡œê·¸(binlog, WAL ë“±) ë¥¼ ì§€ì†ì ìœ¼ë¡œ ê°ì‹œí•˜ë©´ì„œ
INSERT, UPDATE, DELETE ì´ë²¤íŠ¸ë¥¼ Kafka í† í”½ìœ¼ë¡œ ìŠ¤íŠ¸ë¦¬ë°í•©ë‹ˆë‹¤.

ì´ë•ŒëŠ” ë” ì´ìƒ ì „ì²´ í…Œì´ë¸”ì„ ì½ì§€ ì•Šê³ , â€œë³€ê²½ëœ ë ˆì½”ë“œë§Œâ€ ì „ì†¡í•©ë‹ˆë‹¤.


- ì´ˆê¸° ìŠ¤ëƒ…ìƒ·ì€ ê²°êµ­ ì´ëŸ° SQLì„ ëª¨ë“  í…Œì´ë¸”ì— ëŒ€í•´ ìˆ˜í–‰í•˜ëŠ” ê²ƒê³¼ ê°™ìŠµë‹ˆë‹¤:

SELECT * FROM table;


ì¦‰,

í…Œì´ë¸” í¬ê¸°ê°€ í¬ë©´ â†’ ì „ì²´ ìŠ¤ìº”(Full Table Scan)

ë„¤íŠ¸ì›Œí¬ ì „ì†¡ (DB â†’ Kafka Connect)

JSON ì§ë ¬í™” â†’ Kafka ë°œí–‰
ê¹Œì§€ ë‹¤ í¬í•¨ë˜ë‹ˆ, DB I/O, ë„¤íŠ¸ì›Œí¬, Kafka ì „ì†¡ ì§€ì—°ì´ í•œêº¼ë²ˆì— ëˆ„ì ë©ë‹ˆë‹¤.

ğŸ‘‰ ìˆ˜ë°±ë§Œ~ìˆ˜ì²œë§Œ í–‰ ë‹¨ìœ„ë©´ ìˆ˜ì‹­ ë¶„~ìˆ˜ ì‹œê°„ ì´ìƒ ê±¸ë¦´ ìˆ˜ë„ ìˆì–´ìš”.

âš™ï¸ 2ï¸âƒ£ Debeziumì´ ì œê³µí•˜ëŠ” ìµœì í™” ì „ëµë“¤
âœ… (1) Snapshot ëª¨ë“œ ì œì–´

- Debezium ì„¤ì • `snapshot.mode`ë¡œ ìŠ¤ëƒ…ìƒ· ë°©ì‹ì„ ì œì–´í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.

| ëª¨ë“œ             | ì„¤ëª…                                    |
| -------------- | ------------------------------------- |
| `initial`      | (ê¸°ë³¸ê°’) ì „ì²´ ë°ì´í„°ë¥¼ í•œ ë²ˆ ì½ì€ ë’¤ binlogë¡œ ì „í™˜     |
| `schema_only`  | ìŠ¤í‚¤ë§ˆë§Œ ê°€ì ¸ì˜¤ê³  ì‹¤ì œ ë°ì´í„°ëŠ” binlogë¡œë§Œ ë°˜ì˜         |
| `never`        | ìŠ¤ëƒ…ìƒ· ìƒëµ, **ì´ë¯¸ targetì´ ë™ê¸°í™”ë˜ì–´ ìˆëŠ” ê²½ìš° ì‚¬ìš©** |
| `initial_only` | binlogë¡œ ë„˜ì–´ê°€ì§€ ì•Šê³  ìŠ¤ëƒ…ìƒ·ê¹Œì§€ë§Œ ìˆ˜í–‰             |

**Sink Connector**
- Kafka í† í”½ì— ì €ì¥ëœ ë°ì´í„°ë¥¼ ì™¸ë¶€ ì‹œìŠ¤í…œìœ¼ë¡œ ë‚´ë³´ë‚´ëŠ” ì—­í• 

- ì»¤ë„¥í„°ê°€ êµ¬í˜„í•˜ê±°ë‚˜ ì‚¬ìš©í•˜ëŠ” ëª¨ë“  í´ë˜ìŠ¤ëŠ” ì»¤ë„¥í„° í”ŒëŸ¬ê·¸ì¸(connector plugin) ì•ˆì— ì •ì˜ë˜ì–´ ìˆìŠµë‹ˆë‹¤.
- ì¦‰, â€œì»¤ë„¥í„° í”ŒëŸ¬ê·¸ì¸(plugin)â€ì€ ì½”ë“œ(í´ë˜ìŠ¤, ì„¤ì • ë“±)ê°€ ë“¤ì–´ ìˆëŠ” êµ¬í˜„ ë‹¨ìœ„, â€œì»¤ë„¥í„° ì¸ìŠ¤í„´ìŠ¤(instance)â€ëŠ” ê·¸ í”ŒëŸ¬ê·¸ì¸ì„ ì‹¤ì œë¡œ ì‹¤í–‰ ì¤‘ì¸ ì‘ì—… ë‹¨ìœ„ë¼ê³  í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.

- ë‘˜ ë‹¤ â€œì»¤ë„¥í„°(connector)â€ë¼ê³  ë¶€ë¥´ê¸°ë„ í•˜ì§€ë§Œ, ë§¥ë½ì— ë”°ë¼ ì˜ë¯¸ê°€ êµ¬ë¶„ë©ë‹ˆë‹¤.
- ì˜ˆë¥¼ ë“¤ì–´, â€œinstall a connector(ì»¤ë„¥í„°ë¥¼ ì„¤ì¹˜í•œë‹¤)â€ â†’ í”ŒëŸ¬ê·¸ì¸(plugin)ì„ ì˜ë¯¸ â€œcheck the status of a connector(ì»¤ë„¥í„° ìƒíƒœë¥¼ í™•ì¸í•œë‹¤)â€ â†’ ì¸ìŠ¤í„´ìŠ¤(instance)ë¥¼ ì˜ë¯¸

- ConfluentëŠ” ì‚¬ìš©ìê°€ ê°€ëŠ¥í•œ í•œ [ê¸°ì¡´ ì»¤ë„¥í„°](https://www.confluent.io/product/connectors)ë¥¼ í™œìš©í•  ê²ƒì„ ê¶Œì¥

â€» Confluent ?
> https://www.confluent.io/

- Apache Kafkaì˜ ìƒìš© ë°°í¬íŒì„ ë§Œë“  íšŒì‚¬ì´ì, Kafkaì˜ ì°½ì‹œìì¸ Jay Krepsê°€ ê³µë™ ì°½ë¦½í•œ íšŒì‚¬

| í•­ëª©                     | ì„¤ëª…                                                   |
| ---------------------- | ---------------------------------------------------- |
| **Kafka Connect**      | Apache Kafkaì˜ ê³µì‹ ì»´í¬ë„ŒíŠ¸ (ë°ì´í„° í†µí•© í”„ë ˆì„ì›Œí¬)                 |
| **Confluent**          | Kafka ë° Connectë¥¼ í¬í•¨í•œ ìƒìš© ë°°í¬/ìš´ì˜ í”Œë«í¼                    |
| **Confluent Platform** | Kafka Connect + Schema Registry + ksqlDB + ê´€ë¦¬ë„êµ¬ ë“± í¬í•¨ |
| **Confluent Cloud**    | ì™„ì „ê´€ë¦¬í˜• Kafka ì„œë¹„ìŠ¤ (Kafka Connect í¬í•¨)                   |


### 2. Tasks
> Taskê°€ ì‹¤ì œë¡œ ë°ì´í„°ë¥¼ ë³µì‚¬í•˜ëŠ” ì‘ì—…ì„ ìˆ˜í–‰

- ê° ì»¤ë„¥í„° ì¸ìŠ¤í„´ìŠ¤(connector instance)ëŠ” ì—¬ëŸ¬ ê°œì˜ íƒœìŠ¤í¬(task)ë¥¼ ì¡°ì •
-  ì»¤ë„¥í„°ê°€ í•˜ë‚˜ì˜ ì‘ì—…(job)ì„ ì—¬ëŸ¬ íƒœìŠ¤í¬ë¡œ ë‚˜ëˆ„ì–´ ë³‘ë ¬ë¡œ ì‹¤í–‰í•  ìˆ˜ ìˆê²Œ í•¨ìœ¼ë¡œì¨, Kafka ConnectëŠ” ë³‘ë ¬ ì²˜ë¦¬(parallelism) ì™€ í™•ì¥ ê°€ëŠ¥í•œ ë°ì´í„° ë³µì œ(scalable data copying) ë¥¼ ë³µì¡í•œ ì„¤ì • ì—†ì´ë„ ê¸°ë³¸ì ìœ¼ë¡œ ì§€ì›

- ê° íƒœìŠ¤í¬ ìì²´ëŠ” ë‚´ë¶€ì ìœ¼ë¡œ ìƒíƒœ(state)ë¥¼ ì €ì¥í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤.
- ëŒ€ì‹  íƒœìŠ¤í¬ì˜ ìƒíƒœ ì •ë³´ëŠ” Kafkaì˜ íŠ¹ë³„í•œ í† í”½ì— ì €ì¥ë©ë‹ˆë‹¤:
  - `config.storage.topic`
  - `status.storage.topic`

- ì´ ìƒíƒœë“¤ì€ í•´ë‹¹ ì»¤ë„¥í„° ì¸ìŠ¤í„´ìŠ¤ê°€ ê´€ë¦¬í•©ë‹ˆë‹¤. ì¦‰, íƒœìŠ¤í¬ëŠ” ë¬´ìƒíƒœ(stateless) ë¡œ ì„¤ê³„ë˜ì–´ ìˆê³ , í•„ìš”í•  ë•Œë§ˆë‹¤ Kafka ë‚´ë¶€ í† í”½ì„ í†µí•´ ìƒíƒœë¥¼ ë³µêµ¬í•˜ê±°ë‚˜ ê´€ë¦¬í•  ìˆ˜ ìˆë‹¤.
- íƒœìŠ¤í¬ëŠ” ì–¸ì œë“ ì§€ ì‹œì‘(start), ì¤‘ì§€(stop), ì¬ì‹œì‘(restart) í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤. ì´ëŸ° êµ¬ì¡° ë•ë¶„ì— Kafka ConnectëŠ” ì¥ì•  ë³µêµ¬(resilience) ì™€ í™•ì¥ì„±(scalability) ì„ ë™ì‹œì— ê°–ì¶˜ ì•ˆì •ì ì¸ ë°ì´í„° íŒŒì´í”„ë¼ì¸ì„ ì œê³µ

![img.png](/assets/img/kafka-connect-img1.png)
(ì¶œì²˜ : [https://docs.confluent.io/platform/current/connect/index.html](https://docs.confluent.io/platform/current/connect/index.html))

**Task Rebalancing**
- Kafka Connectì—ì„œ ì»¤ë„¥í„°ê°€ í´ëŸ¬ìŠ¤í„°ì— ì²˜ìŒ ë“±ë¡ë˜ë©´, í´ëŸ¬ìŠ¤í„° ë‚´ì˜ ëª¨ë“  ì›Œì»¤(worker)ë“¤ì´ í˜‘ë ¥í•˜ì—¬ ëª¨ë“  ì»¤ë„¥í„°ì™€ íƒœìŠ¤í¬ë¥¼ ì¬ë¶„ë°°(rebalance) í•©ë‹ˆë‹¤.
- ì´ ê³¼ì •ì„ í†µí•´ **ê° ì›Œì»¤ëŠ” ëŒ€ëµ ë™ì¼í•œ ì–‘ì˜ ì‘ì—…ì„ ë‹´ë‹¹**í•˜ê²Œ ë©ë‹ˆë‹¤.

- ë¦¬ë°¸ëŸ°ì‹± ì ˆì°¨ëŠ” ë‹¤ìŒê³¼ ê°™ì€ ìƒí™©ì—ì„œë„ ìˆ˜í–‰ë©ë‹ˆë‹¤:
  - ì»¤ë„¥í„°ê°€ í•„ìš”í•œ íƒœìŠ¤í¬ ê°œìˆ˜ë¥¼ ëŠ˜ë¦¬ê±°ë‚˜ ì¤„ì¼ ë•Œ
  - ì»¤ë„¥í„°ì˜ ì„¤ì •ì´ ë³€ê²½ë  ë•Œ
  - ì›Œì»¤ê°€ ì¥ì• ë¡œ ì¸í•´ ì¤‘ë‹¨ë˜ì—ˆì„ ë•Œ, ë‚¨ì•„ ìˆëŠ” í™œì„± ì›Œì»¤(active workers)ë“¤ë¡œ íƒœìŠ¤í¬ê°€ ì¬ë¶„ë°°ë¨

- ì¦‰, í´ëŸ¬ìŠ¤í„°ëŠ” í•­ìƒ **ë¶€í•˜ë¥¼ ê· ë“±í•˜ê²Œ ë¶„ì‚°ì‹œí‚¤ëŠ” ë°©í–¥ìœ¼ë¡œ ìë™ ì¡°ì •**ëœë‹¤.

- íƒœìŠ¤í¬ê°€ ê°œë³„ì ìœ¼ë¡œ ì‹¤íŒ¨í–ˆì„ ë•Œ(task failure)ëŠ” ë¦¬ë°¸ëŸ°ì‹±ì´ ìë™ìœ¼ë¡œ íŠ¸ë¦¬ê±°ë˜ì§€ ì•ŠëŠ”ë‹¤.
  - íƒœìŠ¤í¬ ì‹¤íŒ¨ëŠ” ì¼ë°˜ì ì¸ ìš´ì˜ ì‹œë‚˜ë¦¬ì˜¤ê°€ ì•„ë‹Œ ì˜ˆì™¸ì ì¸ ìƒí™©ìœ¼ë¡œ ê°„ì£¼ë˜ê¸° ë•Œë¬¸ì…ë‹ˆë‹¤.
  - ë”°ë¼ì„œ, ì‹¤íŒ¨í•œ íƒœìŠ¤í¬ëŠ” Kafka Connect í”„ë ˆì„ì›Œí¬ê°€ ìë™ìœ¼ë¡œ ì¬ì‹œì‘í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤.
  - ëŒ€ì‹  REST API ë¥¼ í†µí•´ ìˆ˜ë™ìœ¼ë¡œ ì¬ì‹œì‘í•´ì•¼ í•©ë‹ˆë‹¤.

![img.png](/assets/img/kafka-connect-img2.png)
=> Task failover example showing how tasks rebalance in the event of a worker failure.

(ì¶œì²˜ : [https://docs.confluent.io/platform/current/connect/index.html](https://docs.confluent.io/platform/current/connect/index.html))


### 3. Workers
> ì»¤ë„¥í„°(Connector) ì™€ íƒœìŠ¤í¬(Task) ëŠ” ë…¼ë¦¬ì ì¸ ì‘ì—… ë‹¨ìœ„ì´ë¯€ë¡œ, ì´ë“¤ì´ ì‹¤ì œë¡œ ì‹¤í–‰ë˜ê¸° ìœ„í•´ì„œëŠ” ì–´ë–¤ í”„ë¡œì„¸ìŠ¤(process) ìœ„ì— ìŠ¤ì¼€ì¤„ë§ë˜ì–´ì•¼ í•©ë‹ˆë‹¤. <br>
> Kafka Connectì—ì„œëŠ” ì´ëŸ¬í•œ í”„ë¡œì„¸ìŠ¤ë¥¼ ì›Œì»¤(Worker) ë¼ê³  ë¶€ë¦…ë‹ˆë‹¤.

**Standalone Workers (ë‹¨ì¼ ëª¨ë“œ ì›Œì»¤)**
- Standalone ëª¨ë“œëŠ” ê°€ì¥ ë‹¨ìˆœí•œ ì‹¤í–‰ ëª¨ë“œì…ë‹ˆë‹¤.
  í•˜ë‚˜ì˜ í”„ë¡œì„¸ìŠ¤ê°€ ëª¨ë“  ì»¤ë„¥í„°ì™€ íƒœìŠ¤í¬ë¥¼ ì§ì ‘ ì‹¤í–‰í•©ë‹ˆë‹¤.

- íŠ¹ì§•:
  - ì„¤ì •ì´ ë§¤ìš° ê°„ë‹¨ (ë‹¨ì¼ í”„ë¡œì„¸ìŠ¤ë§Œ ì‹¤í–‰)
  - ê°œë°œ ì´ˆê¸° ë‹¨ê³„ë‚˜ í…ŒìŠ¤íŠ¸, ë˜ëŠ” ë‹¨ì¼ í˜¸ìŠ¤íŠ¸ì—ì„œ ë¡œê·¸ë¥¼ ìˆ˜ì§‘í•˜ëŠ” ë“±ì˜ ê°„ë‹¨í•œ ìƒí™©ì— ì í•©
  - ëª¨ë“  ì‹¤í–‰ì´ í•˜ë‚˜ì˜ í”„ë¡œì„¸ìŠ¤ì—ì„œ ì²˜ë¦¬ë¨

- ì œí•œì :
  - í™•ì¥ì„±(scalability) ì´ ì œí•œë¨ (í”„ë¡œì„¸ìŠ¤ 1ê°œê°€ ì „ë¶€)
  - ì¥ì•  ë³µêµ¬(fault tolerance) ë¶ˆê°€ëŠ¥ (í”„ë¡œì„¸ìŠ¤ê°€ ì£½ìœ¼ë©´ ì „ì²´ ì¤‘ë‹¨)
  - ì™¸ë¶€ ëª¨ë‹ˆí„°ë§ì„ ë¶™ì´ì§€ ì•Šìœ¼ë©´ ìë™ ë³µêµ¬ ê¸°ëŠ¥ ì—†ìŒ

**Distributed Workers (ë¶„ì‚° ëª¨ë“œ ì›Œì»¤)**
> Kafka Connectì˜ í™•ì¥ì„±(scalability)ê³¼ ìë™ ì¥ì•  ë³µêµ¬(fault tolerance)ë¥¼ ì œê³µí•˜ëŠ” ìš´ì˜ í™˜ê²½ìš© ëª¨ë“œ

- íŠ¹ì§•:
  - ì—¬ëŸ¬ ì›Œì»¤ í”„ë¡œì„¸ìŠ¤ë¥¼ ë™ì¼í•œ group.id ë¡œ ì‹¤í–‰í•˜ë©´, ì´ë“¤ì´ í•˜ë‚˜ì˜ Connect í´ëŸ¬ìŠ¤í„°ë¥¼ í˜•ì„±í•¨.
  - ì›Œì»¤ë“¤ì´ ì„œë¡œ í˜‘ë ¥í•˜ì—¬ ì»¤ë„¥í„°ì™€ íƒœìŠ¤í¬ë¥¼ ìë™ìœ¼ë¡œ ë¶„ì‚° ë°°ì¹˜.
  - ì›Œì»¤ë¥¼ ì¶”ê°€í•˜ê±°ë‚˜ ì¤‘ë‹¨í•˜ê±°ë‚˜ ì¥ì• ê°€ ë°œìƒí•˜ë©´,  ë‚¨ì€ ì›Œì»¤ë“¤ì´ ì´ë¥¼ ê°ì§€í•˜ê³  íƒœìŠ¤í¬ë¥¼ ìë™ ì¬ë¶„ë°°(rebalance) í•¨.
  - ì´ ê³¼ì •ì€ Kafka Consumer Group ë¦¬ë°¸ëŸ°ì‹±ê³¼ ìœ ì‚¬í•œ ë°©ì‹ìœ¼ë¡œ ë™ì‘í•¨.

- ì˜ˆì‹œ:
  - Worker A: group.id = connect-cluster-a
  - Worker B: group.id = connect-cluster-a
  - ë‘ ì›Œì»¤ëŠ” ìë™ìœ¼ë¡œ í•˜ë‚˜ì˜ í´ëŸ¬ìŠ¤í„° connect-cluster-a ë¥¼ í˜•ì„±í•¨.

![img.png](/assets/img/kafka-connect-img3.png)
=> A three-node Kafka Connect distributed mode cluster. Connectors (monitoring the source or sink system for changes that require reconfiguring tasks) and tasks (copying a subset of a connectorâ€™s data) are balanced across the active workers. The division of work between tasks is shown by the partitions that each task is assigned.

(ì¶œì²˜ : [https://docs.confluent.io/platform/current/connect/index.html](https://docs.confluent.io/platform/current/connect/index.html))

### 4. Converters

### 5. Transforms

### 6. Dead Letter Queue

- êµ¬ì„±ìš”ì†Œ
Tasks: The implementation of how data is copied to or from Kafka
Workers: The running processes that execute connectors and tasks
Converters: The code used to translate data between Connect and the system sending or receiving data
Transforms: Simple logic to alter each message produced by or sent to a connector
Dead Letter Queue: How Connect handles connector errors




## Debezium
> DB ë³€í™”ë¥¼ ê°ì§€í•˜ëŠ” ì»´í¬ë„ŒíŠ¸ ?

- Debezium is an open source distributed platform for change data capture.
- Start it up, point it at your databases, and your apps can start responding to all of the inserts, updates, and deletes that other apps commit to your databases.

## Kafka Connectì™€ Debezium ê´€ê³„
> JDBC Driverì™€ êµ¬í˜„ì²´ë“¤ì˜ ê´€ê³„ì™€ ìœ ì‚¬ ?

**Kafka Connect = â€œí”Œë«í¼â€ (JDBCì™€ ìœ ì‚¬í•œ ì¸í„°í˜ì´ìŠ¤ ì œê³µ)**
- Kafka ConnectëŠ” **â€œì»¤ë„¥í„°ê°€ ì–´ë–»ê²Œ Kafkaì™€ ë°ì´í„°ë¥¼ ì£¼ê³ ë°›ì„ì§€â€**ì— ëŒ€í•œ í‘œì¤€í™”ëœ APIë¥¼ ì œê³µí•©ë‹ˆë‹¤.
- ì˜ˆë¥¼ ë“¤ì–´ JDBCì—ì„œ Connection, Statement, ResultSet ê°™ì€ ê³µí†µ ì¸í„°í˜ì´ìŠ¤ë¥¼ ì •ì˜í•˜ë“¯,
- Kafka ConnectëŠ” SourceConnector, SinkConnector ë“±ì˜ ì¸í„°í˜ì´ìŠ¤ë¥¼ ì •ì˜í•©ë‹ˆë‹¤.
- Debezium, JDBC Sink, Elasticsearch Sink ê°™ì€ ë‹¤ì–‘í•œ ì»¤ë„¥í„°ë“¤ì´ ì´ ì¸í„°í˜ì´ìŠ¤ë¥¼ êµ¬í˜„í•©ë‹ˆë‹¤.

**Debezium = â€œíŠ¹ì • ë°ì´í„° ì†ŒìŠ¤ì— íŠ¹í™”ëœ êµ¬í˜„ì²´â€**
- Debeziumì€ Kafka Connectìš© **Source Connector í”ŒëŸ¬ê·¸ì¸**ì…ë‹ˆë‹¤.
- ì¦‰, Kafka Connectì˜ â€œí‘œì¤€ ê·œê²©â€ì„ ë”°ë¥´ë©´ì„œ, MySQL binlogë¥¼ ì½ê³  ì´ë²¤íŠ¸ë¥¼ Kafkaë¡œ ë°œí–‰í•˜ëŠ” êµ¬í˜„ì²´ì…ë‹ˆë‹¤.
- Debeziumì€ MySQLë¿ ì•„ë‹ˆë¼ PostgreSQL, MongoDB, Oracle ë“±ìš© ì»¤ë„¥í„°ë„ ì œê³µí•´ìš”.

```
Kafka Connect (í”Œë«í¼)
â””â”€â”€ Debezium MySQL Connector (í”ŒëŸ¬ê·¸ì¸)
  â””â”€â”€ MySQL binlog ì½ì–´ì„œ Kafkaë¡œ publish
```

| ìš©ì–´                | ì˜ë¯¸                              | ê´€ê³„                                               |
| ----------------- | ------------------------------- | ------------------------------------------------ |
| **Kafka Connect** | í‘œì¤€ ì¸í„°í˜ì´ìŠ¤(í”„ë ˆì„ì›Œí¬)                 | â€œí™•ì¥ í¬ì¸íŠ¸(Extension Point)â€ë¥¼ ì œê³µí•¨                   |
| **í”ŒëŸ¬ê·¸ì¸ (Plugin)** | Connector êµ¬í˜„ì²´ë¥¼ **íŒ¨í‚¤ì§•í•´ì„œ ë°°í¬í•œ í˜•íƒœ** | JAR íŒŒì¼ë¡œ ë§Œë“¤ì–´ Kafka Connectì— ë¡œë“œë¨                   |
| **Connector êµ¬í˜„ì²´** | Kafka Connect ì¸í„°í˜ì´ìŠ¤ë¥¼ **êµ¬í˜„í•œ ì½”ë“œ** | Java í´ë˜ìŠ¤ë¡œ ì‘ì„±ë¨ (ì˜ˆ: `DebeziumMySqlConnector.java`) |

![img.png](img.png)

## ì‹¤ìŠµ
---

- ì‹¤ì œ ì‚¬ë¡€
  - https://techblog.uplus.co.kr/debezium%EC%9C%BC%EB%A1%9C-db-synchronization-%EA%B5%AC%EC%B6%95%ED%95%98%EA%B8%B0-1b6fba73010f
  - https://techblog.lycorp.co.jp/ko/migrating-large-data-with-kafka-and-etl => cdc ì‚¬ìš©í•´ì„œ DB ë§ˆì´ê·¸ë ˆì´ì…˜

```
ì„±ê³µì ìœ¼ë¡œ ë°œí–‰ëœ ETL ë©”ì‹œì§€ë¥¼ MongoDBì— ì €ì¥í•  ë•Œ ê¸´ ì‹œê°„ì´ ê±¸ë¦°ë‹¤ë©´ ë’¤ì— ì´ì–´ì§€ëŠ” CDC ê¸°ë°˜ ë§ˆì´ê·¸ë ˆì´ì…˜ ì‘ì—…ì—ì„œ ì²˜ë¦¬í•  ë©”ì‹œì§€ì–‘ì´ ë§ì•„ì§‘ë‹ˆë‹¤. ê·¸ë ‡ê²Œ ë˜ë©´ ë©”ì‹œì§€ ë³´ê´€ ê¸°ê°„ì´ ê¸¸ì–´ì§€ë©´ì„œ Kafka ë¦¬ì†ŒìŠ¤ë¥¼ ë” ë§ì´ ì°¨ì§€í•©ë‹ˆë‹¤. ë˜í•œ CDC ê¸°ë°˜ ë§ˆì´ê·¸ë ˆì´ì…˜ ì‘ì—…ì€ ë©±ë“±ì„±ì„ ë³´ì¥í•  ìˆ˜ ìˆë„ë¡ êµ¬ì„±í•˜ê¸´ í–ˆì§€ë§Œ ì˜ˆìƒì¹˜ ëª»í•œ ìƒí™©ì´ ë°œìƒí•  ìˆ˜ë„ ìˆê¸°ì— ë§ˆì´ê·¸ë ˆì´ì…˜ ì‹œê°„ì´ ëŠ˜ì–´ë‚˜ëŠ” ê²ƒì€ í”¼í•˜ê³ ì í–ˆìŠµë‹ˆë‹¤.

ë”°ë¼ì„œ ìµœëŒ€í•œ ë¹ ë¥´ê³  ì•ˆì „í•˜ê²Œ ë©”ì‹œì§€ë¥¼ ì†Œë¹„í•´ ETL ê¸°ë°˜ ë§ˆì´ê·¸ë ˆì´ì…˜ì„ ì™„ë£Œí•´ì•¼ í•œë‹¤ëŠ” ëª©í‘œê°€ ìƒê²¼ìŠµë‹ˆë‹¤. ì¿ ë²„ë„¤í‹°ìŠ¤ì˜ ë¦¬ì†ŒìŠ¤ëŠ” ì¶©ë¶„í•´ì„œ ì²˜ë¦¬ëŸ‰ì„ ë†’ì´ê¸° ìœ„í•´ í† í”½ì˜ íŒŒí‹°ì…˜ì„ ëŠ˜ë¦¬ê³  ê·¸ì— ë§ê²Œ íŒŒë“œë¥¼ ì‹¤í–‰í•  ìˆ˜ ìˆì—ˆëŠ”ë°ìš”. ê³ ë¯¼í–ˆë˜ ì ì€ 'ì–´ë–»ê²Œ MongoDBê°€ ì´ ë†’ì€ ì²˜ë¦¬ëŸ‰ì„ ê°ë‹¹í•  ìˆ˜ ìˆë„ë¡ ë§Œë“¤ê¹Œ?'ì˜€ìŠµë‹ˆë‹¤.

ì§§ì€ ì‹œê°„ì— ë„ˆë¬´ ë§ì€ ë°ì´í„°ê°€ ì‚½ì…ë˜ë©´ ë³µì œê°€ ì„¤ì •ëœ DBì—ì„œëŠ” ë³µì œ ì§€ì—°ì´ ë°œìƒí•  ìˆ˜ ìˆê³ , ì§€ì—°ì´ ë„ˆë¬´ ê¸¸ì–´ì§€ë©´ ì„œë¹„ìŠ¤ ë¶ˆê°€ ìƒíƒœê°€ ë  ìˆ˜ ìˆìŠµë‹ˆë‹¤. ë”°ë¼ì„œ ë³µì œ ì§€ì—°ì´ ë„ˆë¬´ ì»¤ì§„ë‹¤ë©´ ì‚½ì… ì†ë„ ì¡°ì ˆì„ ê³ ë ¤í•´ì•¼ í•©ë‹ˆë‹¤.

ETL ì´í›„ë¶€í„° í˜„ì¬ê¹Œì§€ì˜ ë³€ê²½ ì‚¬í•­ì„ MongoDBì— ì ìš©í•˜ë ¤ë©´ CDC í† í”½ì— ë“¤ì–´ì˜¨ MySQL CDC ë©”ì‹œì§€ë¥¼ MongoDBì— ë°˜ì˜í•˜ë©´ ë˜ëŠ”ë° ì´ë•Œ ì–¸ì œë¶€í„°ì˜ ë©”ì‹œì§€ë¥¼ ì†Œë¹„í•  ê²ƒì¸ì§€ë¥¼ ì •í•´ì•¼ í•©ë‹ˆë‹¤. ì‚¬ì‹¤ ETL ë°ì´í„°ê°€ ì •í™•íˆ ì–´ëŠ ì‹œì ì˜ ë°ì´í„°ì¸ì§€ëŠ” ì•Œ ìˆ˜ ì—†ìœ¼ë©°, ì‹œì ì„ ì •í–ˆì„ ë•Œ ì˜¤ì°¨ê°€ ë°œìƒí•  í™•ë¥ ë„ ë†’ìŠµë‹ˆë‹¤. ë”°ë¼ì„œ ìš°ì„  ëˆ„ë½ëœ ë©”ì‹œì§€ë¥¼ ì—†ì• ê¸° ìœ„í•´ ETLì„ ë‚´ë¦¬ëŠ” ì‹œì  ì§ì „ìœ¼ë¡œ MySQL CDC ì˜¤í”„ì…‹ì„ ì¡°ì ˆí–ˆìŠµë‹ˆë‹¤.

ì´ë ‡ê²Œ ì¡°ì¹˜í•˜ë©´ ëˆ„ë½ëœ ë©”ì‹œì§€ëŠ” ì—†ì„ í…Œì§€ë§Œ ì´ë¯¸ ETL í…Œì´ë¸”ì— ë°˜ì˜ëœ ë©”ì‹œì§€ê°€ ì¡´ì¬í•  ìˆ˜ ìˆëŠ”ë°ìš”. ê° CDC ë©”ì‹œì§€ëŠ” ë©±ë“±ì„±ì´ ë³´ì¥ëœ ë°ì´í„°ê°€ ì•„ë‹ˆê¸°ì— ì¤‘ë³µ ì²˜ë¦¬ë¥¼ í•˜ë©´ ë¬¸ì œê°€ ë°œìƒí•©ë‹ˆë‹¤. ì¦‰, ì¤‘ë³µëœ ë©”ì‹œì§€ëŠ” ë‹¤ì‹œ ì²˜ë¦¬ë˜ì§€ ì•Šê²Œ ë¡œì§ì„ êµ¬í˜„í•´ì•¼ í•©ë‹ˆë‹¤.
=> ì´ë¯¸ì§€ í…Œì´ë¸”ì— updatedDateë¼ëŠ” í•„ë“œê°€ ì¡´ì¬í–ˆê¸°ì— í•´ë‹¹ í•„ë“œë¥¼ ì‚¬ìš©í•´ì„œ ìµœì‹  ë©”ì‹œì§€ë§Œ ì ìš©í•˜ë„ë¡ ë©”ì‹œì§€ë¥¼ íŒë³„í•˜ëŠ” í•¨ìˆ˜ë¥¼ êµ¬í˜„í–ˆìŠµë‹ˆë‹¤. ì´ë¡œì¨ ì¤‘ë³µ ë©”ì‹œì§€ê°€ ë“¤ì–´ì™€ë„ ìµœì‹  ë³€ê²½ ì‚¬í•­ë§Œ ì ìš©í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.
=> fun isNewerMessage(message: Value): Boolean {
        val existingImage = imageRepository.findById(message.id)
        return existingImage.isEmpty || mapper.convertValue(message.updateDate.get(), OffsetDateTime::class.java).isAfter(existingImage.get().updatedDate)

Debezium MySQL ConnectorëŠ” ê¸°ë³¸ì ìœ¼ë¡œ PKë¥¼ ë©”ì‹œì§€ì˜ í‚¤ë¡œ ì‚¬ìš©í•©ë‹ˆë‹¤. ë”°ë¼ì„œ íŒŒí‹°ì…˜ì„ ë¶„ë°°í•  ë•Œ IDê°€ ë‹¤ë¥´ë©´ ë‹¤ë¥¸ íŒŒí‹°ì…˜ìœ¼ë¡œ ë¶„ë°°ë  ìˆ˜ ìˆìŠµë‹ˆë‹¤.

ë©”ì‹œì§€ ì²˜ë¦¬ ìˆœì„œì— ë”°ë¼ ê²°ê³¼ê°€ ë‹¬ë¼ì§€ëŠ” ê²ƒì„ ë§‰ê¸° ìœ„í•´ì„œëŠ” CDC ë©”ì‹œì§€ì˜ í‚¤ë¥¼ ë³€ê²½í•´ì•¼ í•©ë‹ˆë‹¤. ë™ì¼í•œ ì˜ë¯¸ë¥¼ ê°–ëŠ” ë°ì´í„°ëŠ” ê°™ì€ íŒŒí‹°ì…˜ì— í• ë‹¹ë¼ì•¼ ë©±ë“±ì„±ì„ ë³´ì¥í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤. ì €í¬ê°€ ì‚¬ìš©í•˜ê³  ìˆëŠ” Debezium MySQL Connectorì—ì„œëŠ” message.key.columnsë¼ëŠ” ì†ì„±ìœ¼ë¡œ í‚¤ë¥¼ ì •ì˜í•˜ëŠ” ë°©ì‹ì„ ë³€ê²½í•  ìˆ˜ ìˆëŠ”ë°ìš”. ì´ë¥¼ ì´ìš©í•´ ì•„ë˜ì™€ ê°™ì´ ë™ì¼í•œ ì˜ë¯¸ì˜ ë©”ì‹œì§€ëŠ” ê°™ì€ íŒŒí‹°ì…˜ì— í• ë‹¹ë˜ë„ë¡ ì„¤ì •í•´ì„œ CDC ë©”ì‹œì§€ ì²˜ë¦¬ì˜ ë©±ë“±ì„±ì„ ë³´ì¥í–ˆìŠµë‹ˆë‹¤.

"message.key.columns": "db_name.table_name:image_id,reference_id,reference_type"
```

=> ë©±ë“±ì„±, í† í”½/íŒŒí‹°ì…˜, Kafka ë¦¬ì†ŒìŠ¤ ë¶€í•˜, DB ë¶€í•˜, CDC ì‹œì 

- Kafka ì„¤ì¹˜ ë””ë ‰í† ë¦¬ íŠ¸ë¦¬ êµ¬ì¡° (ë©”ì‹œì§€ ë¸Œë¡œì»¤ + Connect í¬í•¨)

```
kafka_2.13-3.7.0/
â”œâ”€â”€ bin/                              â† ì‹¤í–‰ ìŠ¤í¬ë¦½íŠ¸ë“¤
â”‚   â”œâ”€â”€ kafka-server-start.sh          â† âœ… Kafka Broker (ë©”ì‹œì§€ ë¸Œë¡œì»¤) ì‹¤í–‰
â”‚   â”œâ”€â”€ kafka-server-stop.sh
â”‚   â”œâ”€â”€ zookeeper-server-start.sh      â† âœ… ZooKeeper (ë©”íƒ€ë°ì´í„° ê´€ë¦¬, ì¼ë¶€ ë²„ì „)
â”‚   â”œâ”€â”€ kafka-topics.sh                â† í† í”½ ìƒì„±/ì¡°íšŒ
â”‚   â”œâ”€â”€ kafka-console-producer.sh      â† CLI Producer
â”‚   â”œâ”€â”€ kafka-console-consumer.sh      â† CLI Consumer
â”‚   â”œâ”€â”€ kafka-connect-standalone.sh    â† âœ… Kafka Connect ë‹¨ì¼ ëª¨ë“œ ì‹¤í–‰
â”‚   â”œâ”€â”€ kafka-connect-distributed.sh   â† âœ… Kafka Connect ë¶„ì‚° ëª¨ë“œ ì‹¤í–‰
â”‚   â”œâ”€â”€ kafka-producer-perf-test.sh
â”‚   â””â”€â”€ kafka-consumer-groups.sh
â”‚
â”œâ”€â”€ config/                           â† ì„¤ì • íŒŒì¼
â”‚   â”œâ”€â”€ server.properties              â† âœ… Kafka Broker ì„¤ì • (log.dir, listeners ë“±)
â”‚   â”œâ”€â”€ zookeeper.properties           â† ZooKeeper ì„¤ì •
â”‚   â”œâ”€â”€ connect-standalone.properties  â† Connect ë‹¨ì¼ ì‹¤í–‰ìš© ì„¤ì •
â”‚   â”œâ”€â”€ connect-distributed.properties â† Connect í´ëŸ¬ìŠ¤í„°ìš© ì„¤ì •
â”‚   â”œâ”€â”€ producer.properties
â”‚   â””â”€â”€ consumer.properties
â”‚
â”œâ”€â”€ libs/                             â† Kafka ëŸ°íƒ€ì„ JAR ëª¨ìŒ
â”‚   â”œâ”€â”€ kafka-clients-*.jar           â† âœ… Kafka Producer/Consumer API
â”‚   â”œâ”€â”€ kafka_2.13-*.jar              â† Kafka Broker ì„œë²„ ì½”ë“œ
â”‚   â”œâ”€â”€ connect-api-*.jar             â† âœ… Kafka Connect í”„ë ˆì„ì›Œí¬ API
â”‚   â”œâ”€â”€ connect-runtime-*.jar         â† âœ… Kafka Connect ì—”ì§„ (ì»¤ë„¥í„° ì‹¤í–‰ í™˜ê²½)
â”‚   â”œâ”€â”€ kafka-streams-*.jar
â”‚   â”œâ”€â”€ slf4j-*.jar, log4j-*.jar      â† ë¡œê¹… ê´€ë ¨
â”‚   â””â”€â”€ ...
â”‚
â”œâ”€â”€ plugins/                          â† (ì§ì ‘ ìƒì„±) âœ… ì»¤ë„¥í„° í”ŒëŸ¬ê·¸ì¸ ì„¤ì¹˜ ê²½ë¡œ
â”‚   â”œâ”€â”€ debezium-connector-mysql/
â”‚   â”‚   â”œâ”€â”€ debezium-connector-mysql-2.7.0.Final.jar
â”‚   â”‚   â””â”€â”€ ...
â”‚   â””â”€â”€ kafka-connect-jdbc/
â”‚       â”œâ”€â”€ kafka-connect-jdbc-10.7.4.jar
â”‚       â”œâ”€â”€ mysql-connector-java-8.0.33.jar
â”‚       â””â”€â”€ ...
â”‚
â”œâ”€â”€ logs/
â”‚   â”œâ”€â”€ server.log
â”‚   â”œâ”€â”€ connect.log
â”‚   â””â”€â”€ zookeeper.log
â”‚
â””â”€â”€ LICENSE / NOTICE / README
```

brew install zookeeper
brew services start zookeeper



kafka-server-start /usr/local/etc/kafka/server.properties

kafka-topics --bootstrap-server localhost:9092 --list



curl -L -O https://repo1.maven.org/maven2/io/debezium/debezium-connector-mysql/2.7.0.Final/debezium-connector-mysql-2.7.0.Final-plugin.tar.gz



mkdir -p /usr/local/Cellar/kafka/4.1.0/libexec/plugins/debezium-mysql
cp -r debezium-connector-mysql/* /usr/local/Cellar/kafka/4.1.0/libexec/plugins/debezium-mysql/



connect-distributed /usr/local/etc/kafka/connect-distributed.properties
=> plugin.path=/usr/local/Cellar/kafka/4.1.0/libexec/plugins

```
curl -X POST http://localhost:8083/connectors \
  -H "Content-Type: application/json" \
  -d '{
    "name": "mysql-orders-connector",
    "config": {
      "connector.class": "io.debezium.connector.mysql.MySqlConnector",
      "database.hostname": "localhost",
      "database.port": "3306",
      "database.user": "root",
      "database.password": "",
      "database.server.id": "184054",
      "database.server.name": "mysql-cdc",
      "database.include.list": "ordersdb",
      "table.include.list": "ordersdb.orders",
      "include.schema.changes": "false",
      "database.history.kafka.bootstrap.servers": "localhost:9092",
      "database.history.kafka.topic": "schema-changes.orders"
    }
  }'
```
=> {"error_code":400,"message":"Connector configuration is invalid and contains the following 1 error(s):\nThe 'topic.prefix' value is invalid: A value is required\nYou can also find the above list of errors at the endpoint /connector-plugins/{connectorType}/config/validate"}%

```
curl -X POST http://localhost:8083/connectors \
  -H "Content-Type: application/json" \
  -d '{
  "name": "mysql-orders-connector",
  "config": {
    "connector.class": "io.debezium.connector.mysql.MySqlConnector",
    "database.hostname": "localhost",
    "database.port": "3306",
    "database.user": "root",
    "database.password": "",
    "database.server.id": "184054",
    "topic.prefix": "mysql-cdc",
    "database.include.list": "ordersdb",
    "table.include.list": "ordersdb.orders",
    "include.schema.changes": "false",
    "database.history.kafka.bootstrap.servers": "localhost:9092",
    "database.history.kafka.topic": "schema-changes.orders"
  }
}'
```

=> {"error_code":400,"message":"Connector configuration is invalid and contains the following 1 error(s):\nUnable to connect: The server time zone value 'KST' is unrecognized or represents more than one time zone. You must configure either the server or JDBC driver (via the 'connectionTimeZone' configuration property) to use a more specific time zone value if you want to utilize time zone support.\nYou can also find the above list of errors at the endpoint `/connector-plugins/{connectorType}/config/validate`"}%

```
curl -X POST http://localhost:8083/connectors \
  -H "Content-Type: application/json" \
  -d '{
  "name": "mysql-orders-connector",
  "config": {
    "connector.class": "io.debezium.connector.mysql.MySqlConnector",
    "database.hostname": "localhost",
    "database.port": "3306",
    "database.user": "root",
    "database.password": "",
    "database.server.id": "184054",
    "topic.prefix": "mysql-cdc",
    "database.include.list": "ordersdb",
    "table.include.list": "ordersdb.orders",
    "include.schema.changes": "false",
    "schema.history.internal.kafka.bootstrap.servers": "localhost:9092",
    "schema.history.internal.kafka.topic": "schema-changes.orders",
    "database.connectionTimeZone": "Asia/Seoul"
  }
}'
```

=> "database.history.kafka.bootstrap.servers": "localhost:9092",
"database.history.kafka.topic": "schema-changes.orders"
ì´ ì„¤ì •ì€ Debezium 1.x ì‹œì ˆ ë°©ì‹ì¸ë°,
Debezium 2.xì—ì„œëŠ” database.history.* â†’ schema.history.internal.* ë¡œ ë°”ë€Œì—ˆìŠµë‹ˆë‹¤.

ë”°ë¼ì„œ Debeziumì´ KafkaSchemaHistory ì´ˆê¸°í™”ì— ì‹¤íŒ¨í•´ì„œ ë°”ë¡œ í„°ì§€ëŠ” ê²ƒ.



```
curl -X POST http://localhost:8083/connectors \
  -H "Content-Type: application/json" \
  -d '{
  "name": "mysql-orders-connector",
  "config": {
    "connector.class": "io.debezium.connector.mysql.MySqlConnector",
    "database.hostname": "localhost",
    "database.port": "3306",
    "database.user": "",
    "database.password": "",
    "database.server.id": "184054",
    "topic.prefix": "mysql-cdc",
    "database.include.list": "ordersdb",
    "table.include.list": "ordersdb.orders",
    "include.schema.changes": "false",
    "database.connectionTimeZone": "Asia/Seoul",

    "schema.history.internal.kafka.bootstrap.servers": "localhost:9092",
    "schema.history.internal.kafka.topic": "schema-changes.orders"
  }
}'
```

```
ERROR [mysql-orders-connector|task-0] WorkerSourceTask{id=mysql-orders-connector-0} Task threw an uncaught and unrecoverable exception. Task is being killed and will not recover until manually restarted (org.apache.kafka.connect.runtime.WorkerTask:251)
java.lang.NoSuchMethodError: 'org.apache.kafka.clients.consumer.ConsumerRecords org.apache.kafka.clients.consumer.KafkaConsumer.poll(long)'
	at io.debezium.storage.kafka.history.KafkaSchemaHistory.recoverRecords(KafkaSchemaHistory.java:319) ~[debezium-storage-kafka-2.7.0.Final.jar:2.7.0.Final]
	at io.debezium.relational.history.AbstractSchemaHistory.recover(AbstractSchemaHistory.java:100) ~[debezium-core-2.7.0.Final.jar:2.7.0.Final]
	at io.debezium.relational.history.SchemaHistory.recover(SchemaHistory.java:192) ~[debezium-core-2.7.0.Final.jar:2.7.0.Final]
	at io.debezium.relational.HistorizedRelationalDatabaseSchema.recover(HistorizedRelationalDatabaseSchema.java:72) ~[debezium-core-2.7.0.Final.jar:2.7.0.Final]
	at io.debezium.schema.HistorizedDatabaseSchema.recover(HistorizedDatabaseSchema.java:40) ~[debezium-core-2.7.0.Final.jar:2.7.0.Final]
	at io.debezium.connector.common.BaseSourceTask.validateAndLoadSchemaHistory(BaseSourceTask.java:148) ~[debezium-core-2.7.0.Final.jar:2.7.0.Final]
	at io.debezium.connector.mysql.MySqlConnectorTask.start(MySqlConnectorTask.java:134) ~[debezium-connector-mysql-2.7.0.Final.jar:2.7.0.Final]
	at io.debezium.connector.common.BaseSourceTask.start(BaseSourceTask.java:248) ~[debezium-core-2.7.0.Final.jar:2.7.0.Final]
	at org.apache.kafka.connect.runtime.AbstractWorkerSourceTask.initializeAndStart(AbstractWorkerSourceTask.java:288) ~[connect-runtime-4.1.0.jar:?]
	at org.apache.kafka.connect.runtime.WorkerTask.doStart(WorkerTask.java:191) ~[connect-runtime-4.1.0.jar:?]
	at org.apache.kafka.connect.runtime.WorkerTask.doRun(WorkerTask.java:242) ~[connect-runtime-4.1.0.jar:?]
	at org.apache.kafka.connect.runtime.WorkerTask.run(WorkerTask.java:298) ~[connect-runtime-4.1.0.jar:?]
	at org.apache.kafka.connect.runtime.AbstractWorkerSourceTask.run(AbstractWorkerSourceTask.java:83) ~[connect-runtime-4.1.0.jar:?]
	at org.apache.kafka.connect.runtime.isolation.Plugins.lambda$withClassLoader$1(Plugins.java:254) ~[connect-runtime-4.1.0.jar:?]
	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:572) ~[?:?]
	at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:317) ~[?:?]
	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144) ~[?:?]
	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642) ~[?:?]
	at java.base/java.lang.Thread.run(Thread.java:1583) [?:?]
[2025-10-19 22:42:30,693] INFO [mysql-orders-connector|task-0] Stopping down connector (io.debezium.connector.common.BaseSourceTask:406)
```

=> kafka-connect, debezium ê°„ì˜ ë²„ì „ í˜¸í™˜ì„± í•„ìš”

![img.png](kafka-connect-debezium-version.png)
=> https://debezium.io/releases/

### ì‹¤í–‰

```
0. brew services start zookeeper

1. kafka-server-start /usr/local/etc/kafka/server.properties
=> í† í”½ ëª©ë¡ ë³´ê¸° : kafka-topics --bootstrap-server localhost:9092 --list

2. connect-distributed /usr/local/etc/kafka/connect-distributed.properties

3.

curl -X POST http://localhost:8083/connectors \
  -H "Content-Type: application/json" \
  -d '{
  "name": "mysql-orders-connector",
  "config": {
    "connector.class": "io.debezium.connector.mysql.MySqlConnector",
    "database.hostname": "localhost",
    "database.port": "3306",
    "database.user": "root",
    "database.password": "",
    "database.server.id": "184054",
    "topic.prefix": "mysql-cdc",
    "database.include.list": "ordersdb",
    "table.include.list": "ordersdb.orders",
    "include.schema.changes": "false",
    "database.connectionTimeZone": "Asia/Seoul",

    "schema.history.internal.kafka.bootstrap.servers": "localhost:9092",
    "schema.history.internal.kafka.topic": "schema-changes.orders"
  }
}'
```

- debezium-connector-mysql ë””ë ‰í† ë¦¬

```
CHANGELOG.md
CONTRIBUTE.md
COPYRIGHT.txt
LICENSE-3rd-PARTIES.txt
LICENSE.txt
README.md
README_JA.md
README_KO.md
README_ZH.md
antlr4-runtime-4.10.1.jar
debezium-api-3.2.4.Final.jar
debezium-common-3.2.4.Final.jar
debezium-connector-binlog-3.2.4.Final.jar
debezium-connector-mysql-3.2.4.Final.jar
debezium-core-3.2.4.Final.jar
debezium-ddl-parser-3.2.4.Final.jar
debezium-openlineage-api-3.2.4.Final.jar
debezium-storage-file-3.2.4.Final.jar
debezium-storage-kafka-3.2.4.Final.jar
mysql-binlog-connector-java-0.40.2.jar
mysql-connector-j-9.1.0.jar
```

## ë³€ê²½ ê°ì§€ ì´ë²¤íŠ¸ í˜•íƒœ
---

```java
@Component
public class OrderConsumer {

    @KafkaListener(topics = "mysql-cdc.ordersdb.orders", groupId = "cdc-group")
    public void consume(ConsumerRecord<String, String> record) {
        String key = record.key();
        String value = record.value();

        System.out.println("---- CDC Event ----");
        System.out.println("Key: " + key);
        System.out.println("Value: " + value);
        System.out.println("-------------------");
    }

}
```

- Key, Value ë‘˜ ë‹¤ ì•„ë˜ì™€ ê°™ì€ í¬ë§·

```json
{
  "schema" : {
    ...
  },
  "payload" : {
    ...
  }
}
```

**insert**

- Key

```json
{
  "schema" : {
    "type" : "struct",
    "fields" : [ {
      "type" : "int64",
      "optional" : false,
      "field" : "id"
    } ],
    "optional" : false,
    "name" : "mysql-cdc.ordersdb.orders.Key"
  },
  "payload" : {
    "id" : 13
  }
}
```

- Value

```json
{
  "schema" : {
    "type" : "struct",
    "fields" : [ {
      "type" : "struct",
      "fields" : [ {
        "type" : "int64",
        "optional" : false,
        "field" : "id"
      }, {
        "type" : "string",
        "optional" : true,
        "field" : "customer_name"
      }, {
        "type" : "bytes",
        "optional" : true,
        "name" : "org.apache.kafka.connect.data.Decimal",
        "version" : 1,
        "parameters" : {
          "scale" : "2",
          "connect.decimal.precision" : "10"
        },
        "field" : "amount"
      }, {
        "type" : "string",
        "optional" : true,
        "name" : "io.debezium.time.ZonedTimestamp",
        "version" : 1,
        "field" : "created_at"
      } ],
      "optional" : true,
      "name" : "mysql-cdc.ordersdb.orders.Value",
      "field" : "before"
    }, {
      "type" : "struct",
      "fields" : [ {
        "type" : "int64",
        "optional" : false,
        "field" : "id"
      }, {
        "type" : "string",
        "optional" : true,
        "field" : "customer_name"
      }, {
        "type" : "bytes",
        "optional" : true,
        "name" : "org.apache.kafka.connect.data.Decimal",
        "version" : 1,
        "parameters" : {
          "scale" : "2",
          "connect.decimal.precision" : "10"
        },
        "field" : "amount"
      }, {
        "type" : "string",
        "optional" : true,
        "name" : "io.debezium.time.ZonedTimestamp",
        "version" : 1,
        "field" : "created_at"
      } ],
      "optional" : true,
      "name" : "mysql-cdc.ordersdb.orders.Value",
      "field" : "after"
    }, {
      "type" : "struct",
      "fields" : [ {
        "type" : "string",
        "optional" : false,
        "field" : "version"
      }, {
        "type" : "string",
        "optional" : false,
        "field" : "connector"
      }, {
        "type" : "string",
        "optional" : false,
        "field" : "name"
      }, {
        "type" : "int64",
        "optional" : false,
        "field" : "ts_ms"
      }, {
        "type" : "string",
        "optional" : true,
        "name" : "io.debezium.data.Enum",
        "version" : 1,
        "parameters" : {
          "allowed" : "true,first,first_in_data_collection,last_in_data_collection,last,false,incremental"
        },
        "default" : "false",
        "field" : "snapshot"
      }, {
        "type" : "string",
        "optional" : false,
        "field" : "db"
      }, {
        "type" : "string",
        "optional" : true,
        "field" : "sequence"
      }, {
        "type" : "int64",
        "optional" : true,
        "field" : "ts_us"
      }, {
        "type" : "int64",
        "optional" : true,
        "field" : "ts_ns"
      }, {
        "type" : "string",
        "optional" : true,
        "field" : "table"
      }, {
        "type" : "int64",
        "optional" : false,
        "field" : "server_id"
      }, {
        "type" : "string",
        "optional" : true,
        "field" : "gtid"
      }, {
        "type" : "string",
        "optional" : false,
        "field" : "file"
      }, {
        "type" : "int64",
        "optional" : false,
        "field" : "pos"
      }, {
        "type" : "int32",
        "optional" : false,
        "field" : "row"
      }, {
        "type" : "int64",
        "optional" : true,
        "field" : "thread"
      }, {
        "type" : "string",
        "optional" : true,
        "field" : "query"
      } ],
      "optional" : false,
      "name" : "io.debezium.connector.mysql.Source",
      "version" : 1,
      "field" : "source"
    }, {
      "type" : "struct",
      "fields" : [ {
        "type" : "string",
        "optional" : false,
        "field" : "id"
      }, {
        "type" : "int64",
        "optional" : false,
        "field" : "total_order"
      }, {
        "type" : "int64",
        "optional" : false,
        "field" : "data_collection_order"
      } ],
      "optional" : true,
      "name" : "event.block",
      "version" : 1,
      "field" : "transaction"
    }, {
      "type" : "string",
      "optional" : false,
      "field" : "op"
    }, {
      "type" : "int64",
      "optional" : true,
      "field" : "ts_ms"
    }, {
      "type" : "int64",
      "optional" : true,
      "field" : "ts_us"
    }, {
      "type" : "int64",
      "optional" : true,
      "field" : "ts_ns"
    } ],
    "optional" : false,
    "name" : "mysql-cdc.ordersdb.orders.Envelope",
    "version" : 2
  },
  "payload" : {
    "before" : null,
    "after" : {
      "id" : 13,
      "customer_name" : "LEE66",
      "amount" : "Opg=",
      "created_at" : "2025-10-20T14:34:09Z"
    },
    "source" : {
      "version" : "3.2.4.Final",
      "connector" : "mysql",
      "name" : "mysql-cdc",
      "ts_ms" : 1760970849000,
      "snapshot" : "false",
      "db" : "ordersdb",
      "sequence" : null,
      "ts_us" : 1760970849000000,
      "ts_ns" : 1760970849000000000,
      "table" : "orders",
      "server_id" : 1,
      "gtid" : null,
      "file" : "binlog.000040",
      "pos" : 203734562,
      "row" : 0,
      "thread" : 411,
      "query" : null
    },
    "transaction" : null,
    "op" : "c",
    "ts_ms" : 1760970849105,
    "ts_us" : 1760970849105848,
    "ts_ns" : 1760970849105848000
  }
}
```

- update : update ìˆ˜ë§Œí¼ ì´ë²¤íŠ¸ ì˜´

```json
{
  "schema" : {
    ...
  },
  "payload" : {
    "before" : {
      "id" : 8,
      "customer_name" : "LEE22",
      "amount" : "LuA=",
      "created_at" : "2025-10-19T13:40:52Z"
    },
    "after" : {
      "id" : 8,
      "customer_name" : "MOD_LEE22",
      "amount" : "LuA=",
      "created_at" : "2025-10-19T13:40:52Z"
    },
    "source" : {
      "version" : "3.2.4.Final",
      "connector" : "mysql",
      "name" : "mysql-cdc",
      "ts_ms" : 1760885949000,
      "snapshot" : "false",
      "db" : "ordersdb",
      "sequence" : null,
      "ts_us" : 1760885949000000,
      "ts_ns" : 1760885949000000000,
      "table" : "orders",
      "server_id" : 1,
      "gtid" : null,
      "file" : "binlog.000040",
      "pos" : 203733180,
      "row" : 0,
      "thread" : 411,
      "query" : null
    },
    "transaction" : null,
    "op" : "u",
    "ts_ms" : 1760885949152,
    "ts_us" : 1760885949152329,
    "ts_ns" : 1760885949152329000
  }
}
```

```json
{
  "schema" : {
    ...
  },
  "payload" : {
    "before" : {
      "id" : 9,
      "customer_name" : "LEE22",
      "amount" : "LuA=",
      "created_at" : "2025-10-19T14:46:20Z"
    },
    "after" : {
      "id" : 9,
      "customer_name" : "MOD_LEE22",
      "amount" : "LuA=",
      "created_at" : "2025-10-19T14:46:20Z"
    },
    "source" : {
      "version" : "3.2.4.Final",
      "connector" : "mysql",
      "name" : "mysql-cdc",
      "ts_ms" : 1760885949000,
      "snapshot" : "false",
      "db" : "ordersdb",
      "sequence" : null,
      "ts_us" : 1760885949000000,
      "ts_ns" : 1760885949000000000,
      "table" : "orders",
      "server_id" : 1,
      "gtid" : null,
      "file" : "binlog.000040",
      "pos" : 203733180,
      "row" : 1,
      "thread" : 411,
      "query" : null
    },
    "transaction" : null,
    "op" : "u",
    "ts_ms" : 1760885949152,
    "ts_us" : 1760885949152769,
    "ts_ns" : 1760885949152769000
  }
}
```

- delete

```json
{
  "schema" : {
    ...
  },
  "payload" : {
    "before" : {
      "id" : 10,
      "customer_name" : "MOD_LEE",
      "amount" : "LuA=",
      "created_at" : "2025-10-19T14:54:39Z"
    },
    "after" : null,
    "source" : {
      "version" : "3.2.4.Final",
      "connector" : "mysql",
      "name" : "mysql-cdc",
      "ts_ms" : 1760886160000,
      "snapshot" : "false",
      "db" : "ordersdb",
      "sequence" : null,
      "ts_us" : 1760886160000000,
      "ts_ns" : 1760886160000000000,
      "table" : "orders",
      "server_id" : 1,
      "gtid" : null,
      "file" : "binlog.000040",
      "pos" : 203733582,
      "row" : 0,
      "thread" : 411,
      "query" : null
    },
    "transaction" : null,
    "op" : "d",
    "ts_ms" : 1760886160859,
    "ts_us" : 1760886160859853,
    "ts_ns" : 1760886160859853000
  }
}
```

- `payload.op`ì— Create(c), Update(u), Delete(d) ë‚˜ì™€ìˆìŒ

### ë™ì‹œì„± ?
- ë™ì¼í•œ í…Œì´ë¸”ì— ëŒ€í•œ ì´ë²¤íŠ¸ëŠ” ìˆœì„œëŒ€ë¡œ ì²˜ë¦¬ë¼ì•¼í•œë‹¤.
- ì—¬ëŸ¬ ì»¨ìŠˆë¨¸ì—ì„œ ë™ì¼í•œ í…Œì´ë¸” ì´ë²¤íŠ¸ë¥¼ ì²˜ë¦¬í•˜ë©´ ì•ˆë˜ì§€ì•Šì„ê¹Œ ??
- ê·¸ëŸ¼ ì»¨ìŠˆë¨¸ êµ¬ì„±ì„ ì–´ë–»ê²Œí•˜ëŠ”ê²Œ ì¢‹ì„ê¹Œ

## ì‹¤ì „ ì‹œë‚˜ë¦¬ì˜¤
---
> db ë§ˆì´ê·¸ë ˆì´ì…˜ì—ì„œ ì„œë¹„ìŠ¤ ì¤‘ë‹¨ ì‹œê°„ì„ ìµœì†Œí™”í•˜ëŠ”ê±°ì•¼, ì˜ˆë¥¼ ë“¤ì–´ mysql -> oracleë¡œ ì´ê´€í•œë‹¤ê³  í–ˆì„ë•Œ íŠ¹ì • ì‹œì ì˜ ìŠ¤ëƒ…ìƒ· ë°ì´í„°ë¥¼ mysql -> oracleë¡œ ì´ê´€í•˜ê³ , ì´ê´€ë˜ëŠ” ë™ì•ˆ mysqlì— commitëœ ë‚´ì—­ë“¤ì€ CDCë¡œ ìˆ˜ì§‘í•˜ëŠ”ê±°ì§€. ê·¸ë¦¬ê³  ìŠ¤ëƒ…ìƒ· ì´ê´€ì´ ì™„ë£Œë˜ë©´, ì´ê´€ë˜ëŠ” ë™ì•ˆ commitëœ ë‚´ì—­ì— ëŒ€í•œ ì´ë²¤íŠ¸ë“¤ì„ oracleì— ë°˜ì˜í•˜ëŠ”ê±°ì•¼. ê·¸ë˜ì„œ, ìŒ“ì¸ ì´ë²¤íŠ¸ë“¤ì„ ìµœëŒ€í•œ ë¹ ë¥´ê²Œ Oracle DBì— ë°˜ì˜í•˜ê²Œ í•˜ê³ ì‹¶ì€ê±°ì§€.(ëŒ€ì‹  Oracle DBì— í° ë¶€í•˜ëŠ” ì£¼ì§€ ì•Šìœ¼ë©´ì„œ) ê·¸ëŸ¼ íŒŒí‹°ì…˜ ê°œìˆ˜, ì»¨ìŠˆë¨¸ ê·¸ë£¹ êµ¬ì„±ì„ ì–´ë–»ê²Œ í•˜ëŠ”ê²Œ ì¢‹ì„ê²ƒ ê°™ì•„ ? ë‚´ ìƒê°ì—” í‹°ì…˜ : ì»¨ìŠˆë¨¸ ìˆ˜ = 1:1 -> 2:2 -> ì´ëŸ°ì‹ìœ¼ë¡œ ëŠ˜ë ¤ê°€ë©´ì„œ ìµœì ì˜ ê°œìˆ˜ë¥¼ ì°¾ëŠ”ê²Œ ì¢‹ì§€ ì•Šë‚˜ ìƒê°ì´ë“œëŠ”ë°, ê·¸ë¦¬ê³  Oracle db ì´ìƒìˆìœ¼ë©´ ì ê¹ ì´ë²¤íŠ¸ cosumeì„ ë©ˆì¶”ëŠ”? ê·¸ëŸ°ê²ƒë„ ê°€ëŠ¥í•œê°€ ?

- ì¦‰, ì£¼ìš” ëª©í‘œëŠ”:
  - **ì„œë¹„ìŠ¤ ì¤‘ë‹¨ ì—†ì´(ë˜ëŠ” ìµœì†Œë¡œ)** DB ë§ˆì´ê·¸ë ˆì´ì…˜ (Zero Downtime DB Migration)
  - ë§ˆì´ê·¸ë ˆì´ì…˜ ë™ì•ˆ ìŒ“ì¸ DML ì´ë²¤íŠ¸ë¥¼ **ìµœëŒ€í•œ ë¹ ë¥´ê²Œ target dbì— ë°˜ì˜**


### ì •í™•íˆ ì›í•˜ëŠ” ì‹œì ì˜ ì´ë²¤íŠ¸ë¶€í„° ìŒ“ëŠ”ê²Œ ê°€ëŠ¥í• ê¹Œ ?

| ì‹œê°       | ì•¡ì…˜             | ë¹„ê³  |
|----------|-----------| ---- |
| 03:59:57 | Cubrid commit  | |
| 03:59:58 | Cubrid commit  | |
| 03:59:59 | Cubrid commit  | |
| 04:00:00 | ì´ ì‹œì ì˜ ìŠ¤ëƒ…ìƒ·ì„ ê¸°ì¤€ìœ¼ë¡œ MySQLë¡œ ë°ì´í„° ë§ˆì´ê·¸ë ˆì´ì…˜ | |
| 04:00:01 | Cubrid commit | Kafka Connectì—ì„œ ê°ì§€í•´ì„œ ì´ë²¤íŠ¸ ë°œí–‰ |

- ì¦‰, ì •í™•íˆ ìŠ¤ëƒ…ìƒ· ì´í›„ ì»¤ë°‹ë¶€í„°(04:00:01) ì¹´í”„ì¹´ íì— ì ì¬í•˜ëŠ”ê²Œ ê°€ëŠ¥í•œê°€ ?

### ì™„ì „í•œ ë¬´ì¤‘ë‹¨ ë§ˆì´ê·¸ë ˆì´ì…˜ì´ ê°€ëŠ¥í• ê¹Œ ?
> 'ìŠ¤ëƒ…ìƒ· ë§ˆì´ê·¸ë ˆì´ì…˜ -> cdc ì´ë²¤íŠ¸ target dbì— ë™ê¸°í™”' í•˜ë”ë¼ë„ mysql cdc ì´ë²¤íŠ¸ê°€ ê³„ì† ë°œìƒí•˜ëŠ”í•œ ì™„ì „í•˜ê²Œ ë‘ dbê°€ ì¼ì¹˜ëœ ìƒíƒœì¸ ê²½ìš°ëŠ” ì—†ì„ê²ƒ ê°™ì€ë°

í˜„ì‹¤ì ì¸ ëª©í‘œëŠ” â€œNear-Zero Downtimeâ€  ë³´í†µ ì´ëŸ° ì‹ìœ¼ë¡œ ì ‘ê·¼í•©ë‹ˆë‹¤

| ë‹¨ê³„                         | ì„¤ëª…                                                  |
| -------------------------- | --------------------------------------------------- |
| **1ï¸âƒ£ Snapshot Migration** | MySQL ë°ì´í„°ë¥¼ Oracleë¡œ bulk dump/import (ëŒ€ë¶€ë¶„ Read-only) |
| **2ï¸âƒ£ CDC ë™ê¸°í™” ì‹œì‘**         | Debeziumì´ MySQL ë³€ê²½ ì´ë²¤íŠ¸ë¥¼ Oracleì— ì‹¤ì‹œê°„ ë°˜ì˜              |
| **3ï¸âƒ£ ë™ê¸°í™” ìƒíƒœ í™•ì¸**          | Kafka Lagì´ ê±°ì˜ 0ì¼ ë•Œ â†’ Oracleê³¼ MySQLì´ ê±°ì˜ ì¼ì¹˜           |
| **4ï¸âƒ£ ì„œë¹„ìŠ¤ Freeze (ì ê¹)**    | MySQL ì“°ê¸° ì¤‘ë‹¨ or Lock (ìˆ˜ì´ˆ~ìˆ˜ë¶„)                         |
| **5ï¸âƒ£ ì”ì—¬ CDC ì´ë²¤íŠ¸ ë°˜ì˜**      | ë‚¨ì€ ì´ë²¤íŠ¸ ì „ë¶€ Oracleì— ì ìš©                                |
| **6ï¸âƒ£ ì„œë¹„ìŠ¤ DB ì „í™˜**          | ì• í”Œë¦¬ì¼€ì´ì…˜ DB URL â†’ Oracle ë¡œ ë³€ê²½                         |
| **7ï¸âƒ£ Oracle ì“°ê¸° ì¬ê°œ**       | Oracleì—ì„œ ì„œë¹„ìŠ¤ ì •ìƒ ìš´ì˜                                  |


â€» ê°œì¸ì ìœ¼ë¡œ ìƒê°í•´ë³¸ zero downtime
- ì• í”Œë¦¬ì¼€ì´ì…˜ ì¸ìŠ¤í„´ìŠ¤ 3ê°œë¼ê³  ê°€ì •
- 1ê°œë§Œ ë¨¼ì € Oracleë¡œ ë¶™ì„ (1: oracle, 2,3 : mysql)
- oracle -> mysqlë„ cdc êµ¬ì„±
- 1ë²ˆ ì¸ìŠ¤í„´ìŠ¤ëŠ” oracleì— ì»¤ë°‹í•˜ê²Œë¨ - cdc íë¦„ : oracle -> mysql --ì´ë¯¸ ì²˜ë¦¬ëœê±´ì§€ í™•ì¸í•˜ê³  ë°˜ì˜í•˜ì§€ ì•ŠìŒ--> oracle
- 2,3ë²ˆ ì¸ìŠ¤í„´ìŠ¤ëŠ” mysqlì— ì»¤ë°‹í•˜ê²Œë¨ - cdc íë¦„ : mysql -> oracle --ì´ë¯¸ ì²˜ë¦¬ëœê±´ì§€ í™•ì¸í•˜ê³  ë°˜ì˜í•˜ì§€ ì•ŠìŒ--> mysql
- 2,3ë²ˆë„ ìˆœì°¨ì ìœ¼ë¡œ oracleë¡œ ë¶™ìŒ

=> ì´ë¡ ì ìœ¼ë¡œ ì™„ì „ ë¬´ì¤‘ë‹¨ DB ì „í™˜ì´ ê°€ëŠ¥í•œ ì´ìƒì  ì„¤ê³„ì˜ˆìš”. ë‹¤ë§Œ ì‹¤ë¬´ì—ì„œëŠ” ë£¨í”„ ë°©ì§€ / ì¶©ëŒ í•´ê²° / idempotent ì²˜ë¦¬ ë¥¼ ì™„ë²½íˆ êµ¬í˜„í•´ì•¼ í•´ì„œ,
Debezium ë‹¨ë…ìœ¼ë¡  ì–´ë µê³  ì¤‘ê°„ì— custom filtering layerê°€ ê¼­ í•„ìš”í•©ë‹ˆë‹¤.


âš ï¸ (1) ë£¨í”„(Loop) ë°©ì§€ ë¬¸ì œ

ê°€ì¥ ì¹˜ëª…ì ì´ì—ìš”.

MySQL -> Oracle (CDC)
Oracle -> MySQL (CDC)


ì´ë²¤íŠ¸ê°€ round-tripìœ¼ë¡œ ê³„ì† ë„ëŠ” ë¬´í•œ ë£¨í”„ê°€ ë°œìƒí•  ìˆ˜ ìˆì–´ìš”.
ê·¸ë˜ì„œ ë³€ê²½ ì¶œì²˜(source) ë¥¼ êµ¬ë¶„í•´ì•¼ í•©ë‹ˆë‹¤.

ì˜ˆ:

Debezium event headerì— "source.system": "mysql"

Oracle connectorê°€ ì´ê±¸ ê°ì§€í•´ì„œ â€œìê¸° ìì‹ ì´ ë§Œë“  ë³€ê²½â€ì€ ë¬´ì‹œ

Debeziumì˜ source í•„ë“œë‚˜ transaction.idë¥¼ í™œìš©í•˜ê±°ë‚˜,
CDC ì´ë²¤íŠ¸ì— origin tag ë¥¼ ë¶™ì—¬ì•¼ í•´ìš”.

{
"op": "u",
"source": {
"db": "oracle",
"instance": "app-instance-1"
},
"after": { "id": 100, "status": "SHIPPED" }
}


ConsumerëŠ” ì´ê±¸ ë³´ê³ 
â€œì´ë¯¸ Oracleâ†’MySQLì—ì„œ ë°œìƒí•œ ì´ë²¤íŠ¸ë©´ ë‹¤ì‹œ ë°˜ì˜í•˜ì§€ ì•ŠìŒâ€
í•˜ëŠ” ë¡œì§ì„ ë„£ì–´ì•¼ í•©ë‹ˆë‹¤.

âš ï¸ (2) Primary Key ì¶©ëŒ / Conflict í•´ê²°

ì–‘ë°©í–¥ ì“°ê¸°ì—ì„œ ê°™ì€ rowë¥¼ ì–‘ìª½ì—ì„œ ìˆ˜ì •í•˜ë©´ ì¶©ëŒ ë‚©ë‹ˆë‹¤.

ì˜ˆ:

app1 (Oracle) â†’ status = "paid"

app2 (MySQL) â†’ status = "cancelled"

CDCê°€ êµì°¨ ë°˜ì˜í•˜ë©´ ë§ˆì§€ë§‰ commitì´ ì´ê¹ë‹ˆë‹¤.
ì¦‰, ìµœì¢… ì¼ê´€ì„±(eventual consistency) ì´ê³ 
ë™ì‹œ ìˆ˜ì • ì¶©ëŒ(conflict resolution) ì •ì±…ì„ ëª…ì‹œí•´ì•¼ í•©ë‹ˆë‹¤.

ë³´í†µ 3ê°€ì§€ ì „ëµ ì¤‘ í•˜ë‚˜ë¥¼ ì„ íƒí•´ìš”:

ì •ì±…	ì„¤ëª…
Last Write Wins (ê¸°ë³¸)	íƒ€ì„ìŠ¤íƒ¬í”„ ìµœì‹  ë³€ê²½ì´ ìŠ¹ì
Source Priority	Oracle > MySQL ê°™ì€ ìš°ì„ ìˆœìœ„ ë¶€ì—¬
Custom Merge	ì»¬ëŸ¼ë³„ ë¨¸ì§€ ë¡œì§ ì ìš© (ì˜ˆ: ì¬ê³ ëŸ‰ í•©ì‚° ë“±)
âš ï¸ (3) íŠ¸ëœì­ì…˜ ìˆœì„œ ìœ ì§€ (ìˆœì„œ ë¶ˆì¼ì¹˜ ë¬¸ì œ)

Oracle CDCì™€ MySQL CDCëŠ” commit íƒ€ì´ë°ì´ ë‹¤ë¥´ê¸° ë•Œë¬¸ì—
ì„œë¡œ ë°˜ì˜ ìˆœì„œê°€ ë‹¬ë¼ì§ˆ ìˆ˜ ìˆìŠµë‹ˆë‹¤.

ì´ê±´ Kafka partition key ë¥¼ PK ê¸°ë°˜ìœ¼ë¡œ ê³ ì •í•˜ê³ 
Debeziumì˜ transaction.id ë¥¼ í™œìš©í•˜ë©´ ìƒë‹¹ ë¶€ë¶„ ì™„í™”ë©ë‹ˆë‹¤.

âš ï¸ (4) Idempotent ì²˜ë¦¬

ì¤‘ë³µ ì´ë²¤íŠ¸ê°€ ë“¤ì–´ì˜¤ë”ë¼ë„ ì•ˆì „í•˜ê²Œ ë¬´ì‹œí•  ìˆ˜ ìˆê²Œ í•´ì•¼ í•©ë‹ˆë‹¤.

ë°©ë²•:

Oracle/MySQL ì¿¼ë¦¬ì—ì„œ upsert(MERGE INTO, INSERT ... ON DUPLICATE KEY UPDATE) ì‚¬ìš©

CDC consumerëŠ” â€œë³€ê²½ëœ ì»¬ëŸ¼ì´ ì‹¤ì œë¡œ ë‹¤ë¥¼ ë•Œë§Œ updateâ€ ìˆ˜í–‰

âš ï¸ (5) ìŠ¤í‚¤ë§ˆ ì°¨ì´ ë¬¸ì œ

MySQL â†” Oracle ê°„ì—”

ë°ì´í„° íƒ€ì… ì°¨ì´ (VARCHAR vs NVARCHAR, DATETIME vs TIMESTAMP)

AUTO_INCREMENT vs SEQUENCE

NULL/DEFAULT ì²˜ë¦¬ ì°¨ì´
ì´ ì¡´ì¬í•˜ê¸° ë•Œë¬¸ì— CDC ì´ë²¤íŠ¸ ë§¤í•‘ ì‹œ ë³€í™˜ ë ˆì´ì–´ê°€ í•„ìš”í•©ë‹ˆë‹¤.

### í† í”½
- Debeziumì€ `<topic.prefix>.<database>.<table>` ì¡°í•©ìœ¼ë¡œ í† í”½ì„ ìë™ ìƒì„±
- ì˜ˆì‹œ:
```
"topic.prefix": "mysql-cdc",
"database.include.list": "ordersdb,usersdb",
"table.include.list": "ordersdb.orders,ordersdb.payments,usersdb.user_profiles"
```
=> í† í”½ : `mysql-cdc.ordersdb.orders`, `mysql-cdc.ordersdb.payments`, `mysql-cdc.usersdb.user_profiles`

- ìŠ¤ëƒ…ìƒ· ë°ì´í„° ë§ˆì´ê·¸ë ˆì´ì…˜ì´ ì™„ì „ ëë‚˜ê³  ì´ë²¤íŠ¸ consumeì„ ì‹œì‘í•˜ëŠ”ê²Œ ì•„ë‹Œ, ë§ˆì´ê·¸ë ˆì´ì…˜ì´ ëë‚œ í…Œì´ë¸” (í† í”½)ì€ ë¨¼ì € consumeí•˜ëŠ”ê±´ ?
=> Sink Connector ì—¬ëŸ¬ ê°œë¡œ ë¶„ë¦¬
=> Spring Boot Applicationì´ë©´ ?

### íŒŒí‹°ì…˜ / ì»¨ìŠˆë¨¸ ê·¸ë£¹
- ê·¸ë˜ì„œ Debeziumì´ ìƒˆ í† í”½ìœ¼ë¡œ ì´ë²¤íŠ¸ë¥¼ publishí•˜ë©´, Kafka ë¸Œë¡œì»¤ê°€ ë‚´ë¶€ ì„¤ì •ê°’ì„ ê¸°ì¤€ìœ¼ë¡œ ìë™ ìƒì„±í•©ë‹ˆë‹¤.
- Kafkaì—ëŠ” ìë™ ìƒì„± í† í”½ì˜ êµ¬ì„±ì„ ì œì–´í•˜ëŠ” ì„¤ì •ë“¤ì´ ìˆìŠµë‹ˆë‹¤:

| ì„¤ì • í•­ëª©                        | ì„¤ëª…                               | ê¸°ë³¸ê°’    |
| ---------------------------- | -------------------------------- | ------ |
| `auto.create.topics.enable`  | ì¡´ì¬í•˜ì§€ ì•ŠëŠ” í† í”½ìœ¼ë¡œ publishí•  ë•Œ ìë™ ìƒì„± ì—¬ë¶€ | `true` |
| `num.partitions`             | ìë™ ìƒì„±ë˜ëŠ” í† í”½ì˜ ê¸°ë³¸ íŒŒí‹°ì…˜ ìˆ˜             | `1`    |
| `default.replication.factor` | ìë™ ìƒì„±ë˜ëŠ” í† í”½ì˜ ë³µì œë³¸ ê°œìˆ˜               | `1`    |

- Debezium ì…ì¥ì—ì„œëŠ” â€œí† í”½ì„ ì§€ì •â€í•  ë¿, Kafkaê°€ ì–´ë–¤ ì„¤ì •ìœ¼ë¡œ í† í”½ì„ ìƒì„±í• ì§€ëŠ” ë¸Œë¡œì»¤ ì„¤ì •ì— ìœ„ì„

### íŒŒí‹°ì…˜ ìˆ˜ ë³€ê²½ ë°©ë²•

**ë¸Œë¡œì»¤ ì„¤ì • ë³€ê²½ (ê¸€ë¡œë²Œ ê¸°ë³¸ê°’)**
> Kafka ì „ì²´ ê¸°ë³¸ê°’ì„ ë°”ê¿”ì„œ ìë™ ìƒì„± í† í”½ì˜ íŒŒí‹°ì…˜ ìˆ˜ë¥¼ ì¡°ì •í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.

```
# server.properties
num.partitions=4
default.replication.factor=3
```

**í† í”½ ìƒì„± ìŠ¤í¬ë¦½íŠ¸ ì‹¤í–‰**

```
kafka-topics.sh --create \
  --topic mysql-cdc.ordersdb.orders \
  --partitions 4 \
  --replication-factor 3 \
  --bootstrap-server localhost:9092
```

**ìë™ ìƒì„± ë„ê³ , ëª…ì‹œì ìœ¼ë¡œ ê´€ë¦¬**
> ìš´ì˜ í™˜ê²½ì—ì„œëŠ” ë³´í†µ ì´ë ‡ê²Œ í•©ë‹ˆë‹¤

```
auto.create.topics.enable=false
```

### Target DBì—ì„œ ë°›ì„ ë¶€í•˜ ?
> ìˆœì‹ê°„ì— ì»¤ë°‹ì´ ë§ì´ ë°œìƒí•˜ë©´ ?? ê·¼ë° ì„œë¹„ìŠ¤ì¤‘ì¸ DBê°€ ì•„ë‹ˆë‹ˆê¹Œ ê´œì°®ì§€ ì•Šë‚˜ ?

- ë¶€í•˜ ì¡°ì ˆ ë°©ë²• ?

â€œì„œë¹„ìŠ¤ ì¤‘ì´ ì•„ë‹ˆë¼ë©´ ë¶€í•˜ ìì²´ëŠ” ëœ ë¯¼ê°í•˜ì§€ë§Œâ€,
DB ìì²´ì˜ íŠ¸ëœì­ì…˜ ì²˜ë¦¬ êµ¬ì¡°ë‚˜ ë¦¬ì†ŒìŠ¤ ê´€ë¦¬ í•œê³„ ë•Œë¬¸ì—
í•œêº¼ë²ˆì— ì»¤ë°‹ì´ ëª°ë¦¬ë©´ ì‹¤ì œë¡œëŠ” ì‹¬ê°í•œ ì„±ëŠ¥ ì €í•˜ë‚˜ ë³‘ëª©ì´ ìƒê¹ë‹ˆë‹¤.

| ë³‘ëª© ìš”ì†Œ                      | ì¦ìƒ                              |
| -------------------------- | ------------------------------- |
| **Redo Log flush**         | ë””ìŠ¤í¬ I/O ë³‘ëª© (commit latency ê¸‰ìƒìŠ¹) |
| **Undo space ë¶€ì¡±**          | ORA-30036 / rollback segment í™•ì¥ |
| **Row-level lock ê²½í•©**      | PK ì¤‘ë³µ update ì‹œ lock ëŒ€ê¸°          |
| **Buffer cache thrashing** | ëŒ€ëŸ‰ DML ì‹œ cache hit ratio ì €í•˜     |
| **Index maintenance ë¶€í•˜**   | ì¸ë±ìŠ¤ ì¬ì •ë ¬ë¡œ CPU í­ì¦                 |


ê·¸ë˜ì„œ ì‹¤ë¬´ì—ì„œëŠ” â€œCDC ë°°ì¹˜ ì œì–´â€ë¥¼ ë‘¡ë‹ˆë‹¤

CDC consumer (ì˜ˆ: Spring Boot ì• í”Œë¦¬ì¼€ì´ì…˜) ë˜ëŠ” Sink Connector ìª½ì—ì„œ
DB ë°˜ì˜ ì†ë„ë¥¼ ì¸ìœ„ì ìœ¼ë¡œ ì œì–´í•©ë‹ˆë‹¤.

| ì „ëµ                            | ì„¤ëª…                               |
| ----------------------------- | -------------------------------- |
| **â‘  ë°°ì¹˜ í¬ê¸° ì œí•œ (Batch Size)**   | 500ê±´, 1000ê±´ ë‹¨ìœ„ë¡œ ëª¨ì•„ ì»¤ë°‹            |
| **â‘¡ ì§€ì—° ì£¼ì… (Throttle)**        | ì»¤ë°‹ ì‚¬ì´ì— ì§§ì€ sleep(ìˆ˜ ms~ìˆ˜ì‹­ms)       |
| **â‘¢ ë³‘ë ¬ ì œí•œ (Thread Pool)**     | DB insert ìŠ¤ë ˆë“œ ìˆ˜ ì œí•œ (ì˜ˆ: 2~4ê°œ)     |
| **â‘£ íŠ¸ëœì­ì…˜ í¬ê¸° ì¡°ì ˆ**              | auto-commit ëŒ€ì‹  ëª…ì‹œì  commitìœ¼ë¡œ ì¡°ì ˆ   |
| **â‘¤ DLQ (Dead Letter Queue)** | DB ì˜¤ë¥˜ë‚˜ constraint ìœ„ë°˜ ì‹œ ì¬ì²˜ë¦¬ìš© í ë¶„ë¦¬ |


### ì¥ì•  ì‹œë‚˜ë¦¬ì˜¤
- Target DB ì¥ì• ì‹œ
- ì´ë²¤íŠ¸ ìœ ì‹¤
  - connect <--> kafka
  - kafka <--> consumer

- consumer : sync connector vs spring boot application

-----


- Kafka is run as a cluster of one or more servers ?
- TCP ë„¤íŠ¸ì›Œí¬ë¡œ í†µì‹ 

- í† í”½ì€, íŒŒì¼ ì‹œìŠ¤í…œì— ë¹„ìœ í•˜ë©´, 'í´ë”' ê°™ì€ê²ƒ
- ì´ë²¤íŠ¸ëŠ”, í´ë” ì•ˆì˜ íŒŒì¼
- ì´ë²¤íŠ¸ëŠ” ì›í•˜ëŠ” ê¸°ê°„ë™ì•ˆ ì €ì¥ë  ìˆ˜ ìˆë‹¤.
- ê°™ì€ í‚¤ë¥¼ ê°–ëŠ” ì´ë²¤íŠ¸ëŠ”, í† í”½ ë‚´ì˜ ë™ì¼í•œ íŒŒí‹°ì…˜ì— append ëœë‹¤.
- íŠ¹ì • í† í”½ì˜ íŒŒí‹°ì…˜ì„ ì»¨ìŠˆë¨¸ê°€ ì½ì„ ë•Œ, ì´ë²¤íŠ¸ê°€ writeëœ ìˆœì„œëŒ€ë¡œ ì½ëŠ” ê²ƒì„ ë³´ì¥í•œë‹¤.
- ë‚´ê²°í•¨ì„±ì„ ìœ„í•´ í† í”½ì€ ë³´í†µ ë³µì œë³¸ì„ ê´€ë¦¬í•œë‹¤. => 3 ë¸Œë¡œì»¤ ??


https://docs.confluent.io/kafka/design/consumer-design.html

[ì»¨ìŠˆë¨¸]
- fetch requestë¥¼ kafka brokerì—ê²Œ ë³´ë‚¸ë‹¤.
- requestì— offsetì„ ì§€ì •í•˜ê³ , ê·¸ offsetë¶€í„° ì‹œì‘í•˜ëŠ” chunk log(?)ë¥¼ ìˆ˜ì‹ ë°›ëŠ”ë‹¤.
- kafka consumerëŠ” pull-based design
  - consumer ìƒí™©ì— ë§ê²Œ ì´ë²¤íŠ¸ë¥¼ ì²˜ë¦¬í•  ìˆ˜ ìˆë‹¤.

[ì»¨ìŠˆë¨¸ ê·¸ë£¹]
> A consumer group is a single logical consumer implemented with multiple physical consumers "for reasons of throughput and resilience." (https://docs.confluent.io/_glossary.html#term-consumer-group)

- Kafkaì—ì„œ ë°ì´í„°ë¥¼ ì½ëŠ” ë‹¨ìœ„ëŠ” â€œConsumerâ€, ê·¸ Consumer ì—¬ëŸ¬ ê°œë¥¼ í•˜ë‚˜ì˜ Group IDë¡œ ë¬¶ì€ ê²ƒì´ Consumer Groupì…ë‹ˆë‹¤.
- ëª¨ë“  ConsumerëŠ” ë°˜ë“œì‹œ ì–´ë–¤ Groupì— ì†í•´ì•¼ í•©ë‹ˆë‹¤.
- KafkaëŠ” â€œí•˜ë‚˜ì˜ íŒŒí‹°ì…˜ì€ ë™ì‹œì— ì˜¤ì§ í•˜ë‚˜ì˜ Consumerë§Œ ì½ì„ ìˆ˜ ìˆë‹¤.â€(ë‹¨, ì„œë¡œ ë‹¤ë¥¸ ê·¸ë£¹ì´ë©´ ìƒê´€ì—†ìŒ)
  - Each partition is consumed by exactly one consumer within each consumer group at any given time.
- Kafka Brokerê°€ ìë™ìœ¼ë¡œ íŒŒí‹°ì…˜ì„ ê·¸ë£¹ ë‚´ Consumerë“¤ì—ê²Œ ë¶„ë°°(assign) í•©ë‹ˆë‹¤. ì´ë¥¼ Consumer Rebalance ë¼ê³  ë¶€ë¦…ë‹ˆë‹¤.
- Kafka Broker ì¸¡ì—ì„œëŠ”, Group coordinatorê°€ ì»¨ìŠˆë¨¸ ê·¸ë£¹ ë‚´ì˜ ì»¨ìŠˆë¨¸ë“¤ì—ê²Œ ì ì ˆí•˜ê²Œ ë¶€í•˜ë¥¼ ë‚˜ëˆ ì£¼ëŠ” ë“±ì˜ ì—­í• ì„ í•œë‹¤.

â˜… hot partition ì´ìŠˆ ?
=> ì˜ˆë¥¼ ë“¤ì–´, CDCì—ì„œ íŒŒí‹°ì…˜ì„ PKê°’ì„ ê¸°ì¤€ìœ¼ë¡œ ë‚˜ëˆ´ëŠ”ë°, íŠ¹ì • PKë¥¼ ê°€ì§„ ë°ì´í„°ì— DML ìš”ì²­ì´ ë„ˆë¬´ ë§ìœ¼ë©´ ? (ì¸ìŠ¤íƒ€ê·¸ë¨ ì¸í”Œë£¨ì–¸ì„œ ê°™ì€ ?)

ì»¨ìŠˆë¨¸ ìˆ˜ â‰¤ íŒŒí‹°ì…˜ ìˆ˜ ë¡œ ìœ ì§€
â†’ ê°€ì¥ ì¼ë°˜ì ì¸ ê¶Œì¥ ì„¤ì •ì…ë‹ˆë‹¤.

rebalance ?

[íŒŒí‹°ì…˜]
- ê° íŒŒí‹°ì…˜ì€ ì„œë¡œ ë‹¤ë¥¸ ì„œë²„ì— ë¶„ì‚°ë  ìˆ˜ ìˆëŠ”ë°, ì´ëŸ¬í•œ íŠ¹ì§• ë•Œë¬¸ì— í•˜ë‚˜ì˜ í† í”½ì´ ì—¬ëŸ¬ ì„œë²„ì— ê±¸ì³ ìˆ˜í‰ì ìœ¼ë¡œ í™•ì¥ë  ìˆ˜ ìˆë‹¤.

============
Kafka Producerì˜ íŒŒí‹°ì…˜ ê²°ì • ë¡œì§ì€ ì•„ì£¼ ë‹¨ìˆœí•©ë‹ˆë‹¤:

partition = hash(key) % number_of_partitions


ì¦‰, ë©”ì‹œì§€ì— keyê°€ ìˆìœ¼ë©´ ê·¸ keyë¥¼ í•´ì‹œí•´ì„œ íŒŒí‹°ì…˜ì„ ê³ ë¥´ê³ ,
keyê°€ ì—†ìœ¼ë©´ ë¼ìš´ë“œë¡œë¹ˆ(round robin) ìœ¼ë¡œ ëœë¤ ë°°ì •ë©ë‹ˆë‹¤.
Debeziumì€ Kafka Producerë¥¼ ë‚´ë¶€ì ìœ¼ë¡œ ì‚¬ìš©í•˜ë¯€ë¡œ, ì´ ê°™ì€ íŒŒí‹°ì…”ë‹ ê·œì¹™ì„ ê·¸ëŒ€ë¡œ ë”°ë¦…ë‹ˆë‹¤.

[í† í”½ë³„ íŒŒí‹°ì…˜ ê°œìˆ˜ ì •í•˜ê¸°]
> ëª©í‘œ : ìŒ“ì¸ ì´ë²¤íŠ¸ê°€ ìµœëŒ€í•œ ë¹ ë¥´ê²Œ DBì— ë°˜ì˜ë  ìˆ˜ ìˆë„ë¡ (DB ë¶€í•˜ ë†’ìœ¼ë©´ ë»—ë‚˜ ??)

- ì‹¤í—˜
  => ìƒˆë²½ì‹œê°„ëŒ€ì— cdcë¡œ ìˆ˜ì§‘í•´ë³´ê³  ì²˜ë¦¬í•´ë³´ë©´ì„œ ì¡°ì ˆ ?? (íŒŒí‹°ì…˜ : ì¸ìŠ¤í„´ìŠ¤ ìˆ˜ = 1:1 -> 2:2 -> ... ì¡°ì ˆí•´ê°€ë©´ì„œ)
  => ê·¸ëŸ¼ í•˜ë£¨ì— í•œë²ˆë§Œ ì‹¤í—˜ ê°€ëŠ¥í•œê±° ì•„ë‹Œê°€ ??
  => ì‹¤ì œ ìŒ“ì¸ ì´ë²¤íŠ¸ ê¸°ë°˜ìœ¼ë¡œ ê³„ì† ì¡°ì ˆí•´ê°€ë©´ì„œ ì‹¤í—˜í•  ìˆ˜ ìˆë‚˜ ??
  => ì¸ìŠ¤í„´ìŠ¤ ìˆ˜ ì¡°ì ˆí•´ê°€ë©´ì„œ

- ì»¨ìŠˆë¨¸ ê·¸ë£¹ì—ì„œ ì´ë²¤íŠ¸ ì†Œë¹„ ì†ë„(?) ì¡°ì ˆ ê°€ëŠ¥í•œê°€ ?

================

ì‹¤ì „ ê°œìˆ˜ êµ¬ì„±

- ë¸Œë¡œì»¤ ìˆ˜ / íŒŒí‹°ì…˜ ìˆ˜ / ì»¨ìŠˆë¨¸ ìˆ˜ ë“±ë“±

===============

ë‹¤ë¥¸ ê¸°ìˆ ë“¤(Rabbit MQ ë“±)ê³¼ì˜ ì°¨ë³„ì  ?

ë¬¼ë¡  í•˜ë‚˜ì˜ ë©”ì‹œì§€ê°€ ë°œí–‰ë  ë•Œ, ë‹¨ í•˜ë‚˜ì˜ ì‹¤í–‰ë§Œ ì´ë£¨ì–´ì ¸ì•¼ í•˜ëŠ” ìš”êµ¬ì‚¬í•­ì—ì„œëŠ” ì¹´í”„ì¹´ë¥¼ í™œìš©í•˜ëŠ” ê²ƒë³´ë‹¤ëŠ” ë©”ì‹œì§€ íë¥¼ í™œìš©í•˜ëŠ” ê²ƒì´ ëª©ì ì— ë” ë§ëŠ” êµ¬ì¡°ë¼ê³  ë³¼ ìˆ˜ë„ ìˆë‹¤. ê²½ìŸí•˜ëŠ” ì†Œë¹„ì íŒ¨í„´(Competing Consumers Pattern) ì„ ì˜ˆì‹œë¡œ ë“ ë‹¤ë©´, í•´ë‹¹ íŒ¨í„´ì€ ì—¬ëŸ¬ ê°œì˜ ë©”ì‹œì§€ë¥¼ ë¹ ë¥´ê²Œ ì²˜ë¦¬í•´ì•¼ í•  ë•Œ ì»¨ìŠˆë¨¸ì˜ ìˆ˜ë¥¼ ëŠ˜ë ¤ì„œ ê°ê°ì˜ ë©”ì‹œì§€ ì†Œë¹„ ì†ë„ë¥¼ ëŠ˜ë¦¬ëŠ” ê²ƒì„ ë§í•˜ëŠ”ë°, ì´ ë•Œì—ëŠ” íŠ¹ì • ì»¨ìŠˆë¨¸ê°€ ì½ì€ ë©”ì‹œì§€ëŠ” ë‹¤ë¥¸ ì»¨ìŠˆë¨¸ê°€ ì½ì„ ìˆ˜ ì—†ë„ë¡ ëª…í™•í•˜ê²Œ ì†Œë¹„ë˜ì–´ì•¼ í•œë‹¤. ê·¸ë¦¬ê³  ê·¸ëŸ¬í•œ ìƒí™©ì—ì„œëŠ” ì¹´í”„ì¹´ë¥¼ í†µí•œ ë¡œì§ ì²˜ë¦¬ë³´ë‹¤ëŠ” ë©”ì‹œì§€ íë¥¼ í™œìš©í•˜ëŠ”ê²Œ ë§ë‹¤.

[ë¦¬ë°¸ëŸ°ì‹±]
- ë§Œì¼ ì»¨ìŠˆë¨¸ì—ì„œ ì¥ì• ê°€ ë°œìƒí•˜ê±°ë‚˜ ìƒˆë¡œìš´ ì»¨ìŠˆë¨¸ê°€ ì»¨ìŠˆë¨¸ ê·¸ë£¹ì— ì¶”ê°€ë  ë•Œì—ëŠ” ë¦¬ë°¸ëŸ°ì‹±ì´ ë°œìƒí•˜ê³ , ë¦¬ë°¸ëŸ°ì‹± ì´í›„ì—ëŠ” ê° ì»¨ìŠˆë¨¸ì—ê²Œ í• ë‹¹ë˜ëŠ” íŒŒí‹°ì…˜ì´ ë°”ë€” ìˆ˜ë„ ìˆê²Œ ëœë‹¤. ì´ ë•Œ ê°ê°ì˜ ì»¨ìŠˆë¨¸ëŠ” ê° íŒŒí‹°ì…˜ì˜ Committed Offset ë¶€í„° ë©”ì‹œì§€ë¥¼ ì½ì–´ë“¤ì´ê²Œ ëœë‹¤. (Consumed Offset ì´ ì•„ë‹ˆë¼ Committed Offset ì´ë‹¤) ë°”ë¡œ ì´ êµ¬ê°„ì—ì„œ ì¤‘ë³µ ë©”ì‹œì§€ ì´ìŠˆê°€ ë°œìƒí•  ìˆ˜ ìˆë‹¤.
- ì¹´í”„ì¹´ë¥¼ í™œìš©í•œ ë¹„ì¦ˆë‹ˆìŠ¤ êµ¬í˜„ì—ì„œëŠ” Committed Offset ì´í›„ì˜ ë©”ì‹œì§€ êµ¬ê°„ì—ì„œ ì¤‘ë³µ ë©”ì‹œì§• ì´ìŠˆê°€ ë°œìƒí•  ìˆ˜ ìˆë‹¤ëŠ” ê²ƒì„ ì „ì œë¡œ ë‘ê³ , ì»¨ìŠˆë¨¸ê°€ ì´ëŸ¬í•œ ìƒí™©ì„ ìŠ¤ìŠ¤ë¡œ í•´ê²°í•´ì•¼ í•¨ì„ ì¸ì§€í•˜ëŠ” ê²ƒì´ ì¤‘ìš”í•˜ë‹¤.

ì¤‘ë³µ ì²˜ë¦¬ ë°©ì§€ë¥¼ ì–´ë–»ê²Œ í•  ê²ƒì¸ê°€

- stop the world, ì¹´í”„ì¹´ 2.3 ë²„ì „ë¶€í„° ë„ì…ëœ Incremental Cooperative Rebalancing

### kafka connectì— debezium-mysql-connectorë¥¼ ì‚¬ìš©í• ë•Œ, mysql binlogì˜ ë³€ê²½ ì‚¬í•­ì´ ìˆëŠ”ì§€ëŠ” pollingë°©ì‹ìœ¼ë¡œ ê³„ì† í™•ì¸í•˜ëŠ”ê±°ì•¼ ?
> Debezium MySQL ConnectorëŠ” ë‚´ë¶€ì ìœ¼ë¡œ MySQLì˜ replication protocol(MySQL ì„œë²„ì™€ Replica(ìŠ¬ë ˆì´ë¸Œ) ê°„ì˜ TCP ê¸°ë°˜ í†µì‹  í”„ë¡œí† ì½œ)ì„ ê·¸ëŒ€ë¡œ ì‚¬ìš©í•©ë‹ˆë‹¤.
> ì¦‰, MySQL ìŠ¬ë ˆì´ë¸Œ(Replica) ì²˜ëŸ¼ ë™ì‘í•©ë‹ˆë‹¤.

```
        (TCP connection)
MySQL  <---------------->  Debezium MySQL Connector
  â†‘                            â”‚
  â”‚                            â”‚
  â””â”€â”€ binlog events (push) â”€â”€â”€â–¶ â”‚
```

- Debezium MySQL Connector â†’ MySQL ì„œë²„ ê°„ í†µì‹ ì€ ë‹¤ìŒ ìˆœì„œë¡œ ì´ë£¨ì–´ì§„ë‹¤:

| ìˆœì„œ | ë™ì‘                  | ì„¤ëª…                                                |
| -- | ------------------- | ------------------------------------------------- |
| â‘   | TCP ì—°ê²° ìƒì„±           | MySQLì˜ 3306 í¬íŠ¸ë¡œ TCP ì ‘ì† (`handshake`)              |
| â‘¡  | ì¸ì¦ (Handshake)      | replication ê³„ì •(`REPLICATION SLAVE` ê¶Œí•œ)ìœ¼ë¡œ ë¡œê·¸ì¸      |
| â‘¢  | Replication ë“±ë¡      | `COM_REGISTER_SLAVE` ëª…ë ¹ ì „ì†¡                        |
| â‘£  | Binlog Streaming ìš”ì²­ | `COM_BINLOG_DUMP` ë˜ëŠ” `COM_BINLOG_DUMP_GTID` ëª…ë ¹ ì†¡ì‹  |
| â‘¤  | ì´ë²¤íŠ¸ ìˆ˜ì‹  (Push)       | MySQLì´ binlog ì´ë²¤íŠ¸ë¥¼ TCP ìŠ¤íŠ¸ë¦¼ìœ¼ë¡œ Debeziumì— **push**   |
| â‘¥  | Debezium ì²˜ë¦¬         | Debeziumì´ ì´ë²¤íŠ¸ë¥¼ íŒŒì‹± â†’ Kafkaë¡œ publish                |


- MySQLì´ replication í”„ë¡œí† ì½œì„ í†µí•´ binlogë¥¼ â€œë³´ë‚´ì£¼ê¸´ í•˜ì§€ë§Œâ€, ê·¸ê±´ consumerê°€ ë¨¼ì € ìš”ì²­í•œ ê²°ê³¼ë¡œ ì—´ë ¤ ìˆëŠ” ìŠ¤íŠ¸ë¦¼ì„ ìœ ì§€í•˜ëŠ” í˜•íƒœì…ë‹ˆë‹¤.
- ê·¸ë˜ì„œ ì™„ì „í•œ pushë¼ê¸°ë³´ë‹¨ â€œpersistent pull streamâ€ì´ë¼ê³  ë³´ëŠ” ê²Œ ì •í™•í•©ë‹ˆë‹¤.

| êµ¬ë¶„         | ì—­í•                  | ì£¼ì²´                      | ë„¤íŠ¸ì›Œí¬ ë°©í–¥                      |
| ---------- | ------------------ | ----------------------- | ---------------------------- |
| íŠ¸ë¦¬ê±° ê¸°ë°˜ CDC | í…Œì´ë¸” ë³€ê²½ ì‹œ ì´ë²¤íŠ¸ ì§ì ‘ ì‹¤í–‰ | MySQL                   | ë‚´ë¶€(ì¿¼ë¦¬ ì‹¤í–‰)                    |
| ë¡œê·¸ ê¸°ë°˜ CDC  | binlog ì´ë²¤íŠ¸ë¥¼ ì½ìŒ     | **CDC Consumer (pull)** | MySQL â†’ Consumer (streaming) |


**MySQL binlog CDCì˜ ê¸°ë³¸ êµ¬ì¡°**
- MySQLì€ íŠ¸ëœì­ì…˜ ì»¤ë°‹ ì‹œ ë³€ê²½ ë‚´ìš©ì„ binary log (binlog) íŒŒì¼ì— ê¸°ë¡í•©ë‹ˆë‹¤.
- ì´í›„ replica(í˜¹ì€ CDC consumer) ê°€ master(MySQL ì„œë²„)ì— replication í”„ë¡œí† ì½œì„ í†µí•´ ì ‘ì†í•´ì„œ,
binlogì˜ ë³€ê²½ ì´ë²¤íŠ¸ë¥¼ streaming ë°©ì‹ìœ¼ë¡œ ìˆ˜ì‹ (pull) í•©ë‹ˆë‹¤.
- Replica(í˜¹ì€ Debezium, Maxwell, Kafka Connect ê°™ì€ CDC ë„êµ¬)ê°€ COM_BINLOG_DUMP ëª…ë ¹ì„ MySQL ì„œë²„ì— ë³´ëƒ„
- MySQLì€ í•´ë‹¹ ìœ„ì¹˜ë¶€í„° ìƒˆë¡œìš´ binlog ì´ë²¤íŠ¸ë¥¼ ì§€ì†ì ìœ¼ë¡œ ì „ì†¡(stream)
- ReplicaëŠ” ì´ë¥¼ ë°›ì•„ì„œ íŒŒì‹± í›„ Kafka ë“±ìœ¼ë¡œ ì „ë‹¬
- ì¦‰, MySQL ì„œë²„ ì…ì¥ì—ì„œëŠ” í´ë¼ì´ì–¸íŠ¸ ìš”ì²­ì— ëŒ€í•œ ì§€ì†ì ì¸ ì‘ë‹µ ìŠ¤íŠ¸ë¦¼ì„ ë³´ë‚´ëŠ” í˜•íƒœë¡œ, ì™¸í˜•ìƒ â€œpushâ€ì²˜ëŸ¼ ë³´ì´ì§€ë§Œ ì—°ê²° ì£¼ë„ê¶Œì€ consumer(=pull) ì— ìˆìŠµë‹ˆë‹¤.

**ì™œ â€œlog-based CDCê°€ íš¨ìœ¨ì â€ì¸ê°€?**
- CDC ë„êµ¬ê°€ binlogë¥¼ ì½ì„ ë¿, ì‹¤ì œ í…Œì´ë¸”ì´ë‚˜ ì• í”Œë¦¬ì¼€ì´ì…˜ ì¿¼ë¦¬ì—ëŠ” ê´€ì—¬í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤.
- ì¦‰, íŠ¸ë¦¬ê±°ë‚˜ ì¶”ê°€ SELECT ì¿¼ë¦¬ê°€ ì—†ê³ , ë°ì´í„° ë³€ê²½ ì‹œì ì— MySQLì´ ì´ë¯¸ ìƒì„±í•œ ë¡œê·¸ë¥¼ ì¬í™œìš©í•˜ê¸° ë•Œë¬¸ì—,
- ì›ë³¸ DBì˜ ë¶€í•˜ë¥¼ ê±°ì˜ ì¦ê°€ì‹œí‚¤ì§€ ì•ŠìŠµë‹ˆë‹¤.
- ê·¸ë˜ì„œ â€œë¡œê·¸ ê¸°ë°˜ CDCê°€ ì›ë³¸ ì‹œìŠ¤í…œì˜ ì„±ëŠ¥ì— ì˜í–¥ì„ ìµœì†Œí™”í•œë‹¤â€ëŠ” ì„¤ëª…ì´ ì„±ë¦½í•©ë‹ˆë‹¤.

## ì°¸ê³  ìë£Œ
---
- [https://kafka.apache.org/documentation.html#connect](https://kafka.apache.org/documentation.html#connect)
- [https://docs.confluent.io/platform/current/connect/index.html](https://docs.confluent.io/platform/current/connect/index.html)

- [https://debezium.io/documentation/reference/3.2/](https://debezium.io/documentation/reference/3.2//)
